{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from portia.cli import CLIExecutionHooks\n",
    "from portia import *\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Generic, TypeVar, List, Literal\n",
    "import os\n",
    "from notion_client import Client\n",
    "from my_custom_tools.registry import custom_tool_registry\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Fetch the Notion API key and set up client\n",
    "notion_api_key = os.getenv(\"NOTION_API_KEY\")\n",
    "notion_parent_id = os.getenv(\"NOTION_PARENT_ID\")\n",
    "\n",
    "# Initialize the Notion client\n",
    "notion = Client(auth=notion_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = Config.from_default()\n",
    "complete_tool_registry = PortiaToolRegistry(my_config) + custom_tool_registry\n",
    "\n",
    "portia = Portia(config = my_config,\n",
    "                tools = complete_tool_registry,\n",
    "                execution_hooks=CLIExecutionHooks(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 12:21:25.510\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running these tasks: \n",
      "                      - Find and download 1 paper on the topic of Using LLMs for Interior Design using the ArXivTool. \n",
      "                      - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
      "                      - From the full text, extract the core mathematical and scientific concepts required \n",
      "                        to understand the paper. Focus only on generalizable topics that could be included \n",
      "                        in a learning pathway or curriculum—avoid content specific to the study's location, \n",
      "                        data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                      - Then use the TopicSelectorTool on these topics. \n",
      "                      - Then use the Notion Tool to create Notion pages for these topics.\n",
      "                      - \n",
      "\n",
      "                        Take into account these constraints: []\n",
      "                      \u001b[0m\n",
      "\u001b[32m2025-04-12 12:21:40.392\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m222\u001b[0m - \u001b[1mPlan created with 6 steps\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383'}\n",
      "\n",
      "Here are the steps in the generated plan:\n",
      "{\n",
      "  \"task\": \"Retrieve 1 paper on the topic 'Using LLMs for Interior Design' by searching arXiv for relevant research papers.\",\n",
      "  \"inputs\": [],\n",
      "  \"tool_id\": \"arxiv_tool\",\n",
      "  \"output\": \"$arxiv_paper\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Download the paper using the retrieved paper details.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$arxiv_paper\",\n",
      "      \"description\": \"The paper details retrieved from arXiv on the topic 'Using LLMs for Interior Design'.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"download_tool\",\n",
      "  \"output\": \"$downloaded_papers\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Extract the full text from the PDFs available in the local papers folder.\",\n",
      "  \"inputs\": [],\n",
      "  \"tool_id\": \"pdf_reader_tool\",\n",
      "  \"output\": \"$full_text\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"From the full text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum—avoid content specific to the study’s location, data, or outcomes. List only the overarching topics with no extra text.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$full_text\",\n",
      "      \"description\": \"The complete text extracted from the PDFs.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"llm_tool\",\n",
      "  \"output\": \"$extracted_topics\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Select topics from the extracted concepts using a topic selection process.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$extracted_topics\",\n",
      "      \"description\": \"The list of overarching core mathematical and scientific concepts extracted from the full text.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"topic_selector_tool\",\n",
      "  \"output\": \"$selected_topics\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Create pages in Notion for the selected topics.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$selected_topics\",\n",
      "      \"description\": \"The final list of selected topics to be used for creating Notion pages.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"notion_tool\",\n",
      "  \"output\": \"$notion_pages_created\",\n",
      "  \"condition\": null\n",
      "}\n",
      "\n",
      "The plan will now be executed. Please wait...\n",
      "\u001b[32m2025-04-12 12:21:47.042\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m528\u001b[0m - \u001b[1mPlan Run State is updated to PlanRunState.IN_PROGRESS. View in your Portia AI dashboard: https://app.portialabs.ai/dashboard/plan-runs?plan_run_id=prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0\u001b[0m\n",
      "\u001b[32m2025-04-12 12:21:47.053\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 0: Retrieve 1 paper on the topic 'Using LLMs for Interior Design' by searching arXiv for relevant research papers.\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383', 'plan_run': 'prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0'}\n",
      "\u001b[32m2025-04-12 12:21:50.228\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking arXiv Tool with args: {'topic': 'Using LLMs for Interior Design', 'max_results': 1}\u001b[0m\n",
      "\u001b[32m2025-04-12 12:21:54.013\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [{\"title\": \"FlairGPT: Repurposing LLMs for Interior Designs\", \"summary\": \"Interior design involves the careful selection and arrangement of objects to\\ncreate an aesthetically pleasing, functional, and harmonized space that aligns\\nwith the client's design brief. This task is particularly challenging, as a\\nsuccessful design must not only incorporate all the necessary objects in a\\ncohesive style, but also ensure they are arranged in a way that maximizes\\naccessibility, while adhering to a variety of affordability and usage\\nconsiderations. Data-driven solutions have been proposed, but these are\\ntypically room- or domain-specific and lack explainability in their design\\ndesign considerations used in producing the final layout. In this paper, we\\ninvestigate if large language models (LLMs) can be directly utilized for\\ninterior design. While we find that LLMs are not yet capable of generating\\ncomplete layouts, they can be effectively leveraged in a structured manner,\\ninspired by the workflow of interior designers. By systematically probing LLMs,\\nwe can reliably generate a list of objects along with relevant constraints that\\nguide their placement. We translate this information into a design layout\\ngraph, which is then solved using an off-the-shelf constrained optimization\\nsetup to generate the final layouts. We benchmark our algorithm in various\\ndesign configurations against existing LLM-based methods and human designs, and\\nevaluate the results using a variety of quantitative and qualitative metrics\\nalong with user studies. In summary, we demonstrate that LLMs, when used in a\\nstructured manner, can effectively generate diverse high-quality layouts,\\nmaking them a viable solution for creating large-scale virtual scenes. Project\\nwebpage at https://flairgpt.github.io/\", \"link\": \"https://arxiv.org/pdf/2501.04648v1.pdf\"}]\u001b[0m\n",
      "\u001b[32m2025-04-12 12:21:55.462\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 1: Download the paper using the retrieved paper details.\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383', 'plan_run': 'prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0'}\n",
      "\u001b[32m2025-04-12 12:22:04.731\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking download Tool with args: {'papers': [{'title': 'FlairGPT: Repurposing LLMs for Interior Designs', 'link': 'https://arxiv.org/pdf/2501.04648v1.pdf', 'summary': \"Interior design involves the careful selection and arrangement of objects to\\ncreate an aesthetically pleasing, functional, and harmonized space that aligns\\nwith the client's design brief. This task is particularly challenging, as a\\nsuccessful design must not only incorporate all the necessary objects in a\\ncohesive style, but also ensure they are arranged in a way that maximizes\\naccessibility, while adhering to a variety of affordability and usage\\nconsiderations. Data-driven solutions have been proposed, but these are\\ntypically room- or domain-specific and lack explainability in their design\\ndesign considerations used in producing the final layout. In this paper, we\\ninvestigate if large language models (LLMs) can be directly utilized for\\ninterior design. While we find that LLMs are not yet capable of generating\\ncomplete layouts, they can be effectively leveraged in a structured manner,\\ninspired by the workflow of interior designers. By systematically probing LLMs,\\nwe can reliably generate a list of objects along with relevant constraints that\\nguide their placement. We translate this information into a design layout\\ngraph, which is then solved using an off-the-shelf constrained optimization\\nsetup to generate the final layouts. We benchmark our algorithm in various\\ndesign configurations against existing LLM-based methods and human designs, and\\nevaluate the results using a variety of quantitative and qualitative metrics\\nalong with user studies. In summary, we demonstrate that LLMs, when used in a\\nstructured manner, can effectively generate diverse high-quality layouts,\\nmaking them a viable solution for creating large-scale virtual scenes. Project\\nwebpage at https://flairgpt.github.io/\"}]}\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:07.744\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - ✅ Downloaded 0 paper into the 'papers' folder\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:09.270\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 2: Extract the full text from the PDFs available in the local papers folder.\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383', 'plan_run': 'prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0'}\n",
      "\u001b[32m2025-04-12 12:22:12.448\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking PDF reader tool with args: {}\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:15.281\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - {\"Poster.pdf\": \"--- Page 1 ---\\nForecasting coronavirus in Italy with SIRD modelling\\nGabrielle Littlefair\\nOral: https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d1f1304-438b-40e3-b586-abd7011a8903\\nObjectives\\n• Find estimates for the contact, death and recovery rates\\nof coronavirus in Italy using least squares regression.\\n• Identify any issues with the model and data.\\n• Extrapolate the model to see how coronavirus may\\nprogress in the upcoming months.\\nIntroduction\\nThe ﬁrst case of coronavirus in Italy was reported on the 31st\\nJanuary 2020. Between then and the 6th June 2020, 33,846\\npeople died and the total number of cases rose to 234,801 [8].\\n23.3% of Italy’s population is over the age of 65 [5], making it\\nthe second oldest population in the world. This may explain\\nwhy Italy seems especially vulnerable. I have modelled Italy’s\\noutbreak using SIRD modelling. Modelling accurate rates of\\ninfection, recovery and death, along with the basic reproduc-\\ntion number, R0, can be quite challenging due to the high\\nproportion of infections that are undetected. The number of\\ninfections has been estimated to be as high as 63 times as large\\nas the number recorded [3].\\nSIRD Modelling\\nSIRD modelling is based on four diﬀerent groups within the\\npopulation: those who are susceptible (S); those who are in-\\nfected (I); those who have recovered (R); and those who have\\ndied (D).\\nThe governing equations of my model are as follows:\\nS + I\\nβ\\n−→2I\\nI\\nγ\\n−→R\\nI\\nδ\\n−→D\\nWhere β is the contact rate, γ is the rate of recovery, and δ is\\nthe rate of death. From these equations, the following system\\nof ODEs can be found and solved [6]:\\ndS\\ndt = −β\\nNSI\\ndI\\ndt = β\\nNSI −(γ + δ)I\\ndR\\ndt = γI\\ndD\\ndt = δI\\nFitting the Model to the Data\\nI used least squares regression from python’s lmﬁt module to\\nﬁt my SIRD model to my data [7]. I began by assuming that\\nmy rates β, γ and δ were all constant. However, after plotting\\nthe results of this model, I quickly realised that my value of β\\nneeded to decrease with time. Therefore, I decided to deﬁne\\nβ(t) as a function instead. I found this function intuitively\\nusing a negative exponential model multiplied by the β value\\nfound. I also assumed that the initial number of susceptible in\\nItaly was equal to the population: 60,461,828 [1]. The results\\nfor recovery and death rates were as follows:\\nγ = 0.0234\\nδ = 0.0064\\nThe following values of β correspond to the start of the data\\nand the end of lockdown:\\n18/02/2020\\nβ = 0.1473\\n14/05/2020\\nβ = 0.0080\\nFrom these values of β we can see that at the end of lockdown,\\nthe infection rate was much lower, as expected, due to much\\nfewer contacts between those in the susceptible group and those\\nin the infected group.\\nR0\\nAn important feature of modelling epidemics is the basic repro-\\nduction number R0. This number is the number of secondary\\ninfections resulting from a single primary infection. The reason\\nthis value is so important is that it is an indication of whether\\nthe disease will die out (R0 \\< 1), or if it will become an en-\\ndemic (R0 \\> 1) [4]. This value changes when measures are\\nimplemented that reduce the rate of infection, like lockdown.\\nR0 can be found using the following equation [7]:\\nR0 = β(t)\\nγ\\nUsing my model, I have found values of R0 at diﬀerent times:\\n18/02/2020\\nR0 = 6.2929\\n22/04/2020\\nR0 = 1.0052\\n23/04/2020\\nR0 = 0.9542\\n14/05/2020\\nR0 = 0.3405\\nR0 is ﬁrst below 1, meaning that the disease has begun dying\\nout, on the 23rd April 2020, in the middle of the lockdown pe-\\nriod. This suggests that lockdown was eﬀective. When Italy\\nbegan relaxing its lockdown measures, R0 was very small, how-\\never as the lockdown eases and contact rates increase that value\\ncould easily rise once again.\\nAssumptions\\nSIRD modelling has many drawbacks. First of all, the assumes that once you have been infected you are then immune to the virus,\\nwhich has not been proved or disproved for coronavirus yet. If this assumption is proved wrong, the model would be unreliable\\nuntil another category is added in. My model assumes that you become infectious when you become infected (i.e. when you test\\npositive), however, according to Harvard Medical School [2], you actually become infectious up to 72 hours before you show any\\nsymptoms. Another assumption is that there are no births in the population. There are also problems with the accuracy and\\nreliability of the data [8] being used. Many cases of coronavirus go unreported and untested. There could also be a high proportion\\nof asymptomatic cases [3], which will also remain unrecorded.\\nThe Model\\nFigure 1:Data vs Model plotted between 18/02/2020 and 07/06/2020\\nForecast\\nFigure 2:Model plotted between 18/02/2020 and 06/08/2020\\nConclusion\\nAlthough I do not believe that the model I have gener-\\nated is very accurate, it seems that Italy is very much on\\nthe way towards eradicating coronavirus. However, the un-\\nknown proportion of the population that has coronavirus\\nand is asymptomatic, along with the unrecorded cases,\\ncould mean that we may begin to see an upward trend\\nin the number of cases. Potentially even a second peak.\\nGoing forward, I would like to add in more compartments\\ninto my model (such as the exposed compartment), in order\\nto increase the accuracy of the model. This exposed cate-\\ngory would remove the need for a dampener on the rate of\\ninfection, as a contact rate would then also be estimated,\\nmaking a much more reliable model. I would also like to\\ncompare various countries which have now left lockdown\\nin order to see how exiting the lockdown has aﬀected their\\ninfection rates and whether a second spike seems likely.\\nReferences\\n[1] “Our world in data coronavirus.” [Online]. Available:\\nhttps://ourworldindata.org/coronavirus\\n[2] “Harvard health coronavirus.” [Online]. Available:\\nhttps://www.health.harvard.edu/diseases-and-conditions/\\nif-youve-been-exposed-to-the-coronavirus\\n[3] G. C. Calaﬁore, C. Novara, and C. Possieri, “A modiﬁed sir model for\\nthe covid-19 contagion in italy,” Mar 31, 2020. [Online]. Available:\\n[4] K. Nixon and L. Servitje, Endemic.\\nLondon: Palgrave Macmillan\\nLimited, 2016. [Online]. Available: https://ebookcentral.proquest.\\ncom/lib/[SITE_ID]/detail.action?docID=4720003\\n[5] J. B. Dowd, L. Andriano, D. M. Brazel, V. Rotondi, P. Block,\\nX. Ding, Y. Liu, and M. C. Mills, “Demographic science aids in\\nunderstanding the spread and fatality rates of covid-19,” Proceedings\\nof the National Academy of Sciences of the United States of\\nAmerica, vol. 117, no. 18, pp. 9696–9698, May 5, 2020. [Online].\\nAvailable: https://www.ncbi.nlm.nih.gov/pubmed/32300018\\n[6] . K. S. E. Model, “Introduction to epidemic modeling.”\\n[7] J. Fernández-Villaverde, “Estimating and simulating a sird model of\\ncovid-19 for many countries, states, and cities,” 2020. [Online].\\nAvailable: http://www.econis.eu/PPNSET?PPN=1698547927\\n[8] “John hopkins university coronavirus data.” [Online]. Available:\\nhttps://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\"}\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:16.849\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 3: From the full text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum—avoid content specific to the study’s location, data, or outcomes. List only the overarching topics with no extra text.\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383', 'plan_run': 'prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0'}\n",
      "\u001b[32m2025-04-12 12:22:21.156\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking LLM Tool with args: {'task': 'From the full text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum—avoid content specific to the study’s location, data, or outcomes. List only the overarching topics with no extra text.'}\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:25.042\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - 1. SIRD Modelling\n",
      "2. Ordinary Differential Equations (ODEs)\n",
      "3. Least Squares Regression\n",
      "4. Basic Reproduction Number (R0)\n",
      "5. Epidemiological Modelling Assumptions\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:26.473\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 4: Select topics from the extracted concepts using a topic selection process.\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383', 'plan_run': 'prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0'}\n",
      "\u001b[32m2025-04-12 12:22:30.471\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking Topic Selector Tool with args: {'raw_topics': ['1. SIRD Modelling', '2. Ordinary Differential Equations (ODEs)', '3. Least Squares Regression', '4. Basic Reproduction Number (R0)', '5. Epidemiological Modelling Assumptions']}\u001b[0m\n",
      "\n",
      "📚 Please choose one or more topics to learn about:\n",
      "1. SIRD Modelling\n",
      "2. Ordinary Differential Equations (ODEs)\n",
      "3. Least Squares Regression\n",
      "4. Basic Reproduction Number (R0)\n",
      "5. Epidemiological Modelling Assumptions\n",
      "\u001b[32m2025-04-12 12:22:36.073\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [\"SIRD Modelling\", \"Ordinary Differential Equations (ODEs)\"]\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:37.487\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 5: Create pages in Notion for the selected topics.\u001b[0m | {'plan': 'plan-c025de12-2b48-47d8-a54d-d5cb60f27383', 'plan_run': 'prun-9d28f778-fb93-4bad-9750-1b85fef1c6b0'}\n",
      "\u001b[32m2025-04-12 12:22:40.815\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking Notion Tool with args: {'topics': ['SIRD Modelling', 'Ordinary Differential Equations (ODEs)']}\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:48.183\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [{\"topic\": \"SIRD Modelling\", \"page_id\": \"1d36ccbb-ecba-8176-9dac-dbff08b41770\"}, {\"topic\": \"Ordinary Differential Equations (ODEs)\", \"page_id\": \"1d36ccbb-ecba-81dd-9698-eeaff27b296c\"}]\u001b[0m\n",
      "\u001b[32m2025-04-12 12:22:52.812\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[37mportia.portia\u001b[0m:\u001b[37m_log_final_output\u001b[0m:\u001b[37m618\u001b[0m - \u001b[1mFinal output: The tasks involved retrieving a paper on using LLMs for interior design, downloading it, and extracting its full text. However, the downloaded text was unrelated, focusing on SIRD modeling for COVID-19. Core concepts extracted included SIRD Modelling, ODEs, Least Squares Regression, R0, and epidemiological assumptions. The TopicSelectorTool narrowed this to SIRD Modelling and ODEs, for which Notion pages were created. The final output emphasized these selected topics, despite the initial task's focus on interior design.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "constraints = []\n",
    "# topic = input(\"What topic are you interested in covering today?\")\n",
    "# number_of_papers = int(input(\"How many papers do you want to download?\"))\n",
    "topic = \"Using LLMs for Interior Design\"\n",
    "number_of_papers = 1\n",
    "video_preference = False\n",
    "number_of_videos = 2\n",
    "podcast_preference = True\n",
    "\n",
    "task = (\n",
    "            lambda : f\"\"\"You are a research assistant running these tasks: \n",
    "                      - Find and download {number_of_papers} paper{'s' * (number_of_papers > 1)} on the topic of {topic} using the ArXivTool. \n",
    "                      - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
    "                      - From the full text, extract the core mathematical and scientific concepts required \n",
    "                        to understand the paper. Focus only on generalizable topics that could be included \n",
    "                        in a learning pathway or curriculum—avoid content specific to the study's location, \n",
    "                        data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
    "                      - Then use the TopicSelectorTool on these topics. \n",
    "                      - Then use the Notion Tool to create Notion pages for these topics.\n",
    "                      - {video_preference * \"Use the YouTubeTool to find videos on each topic.\"}\n",
    "                      \n",
    "                        Take into account these constraints: {constraints}\n",
    "                      \"\"\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "# Iterate on the plan with the user until they are happy with it\n",
    "with execution_context(end_user_id=\"learning_enthusiast\",):\n",
    "    plan = portia.plan(task())\n",
    "    print(\"\\nHere are the steps in the generated plan:\")\n",
    "    [print(step.model_dump_json(indent=2)) for step in plan.steps]\n",
    "    ready_to_proceed = False\n",
    "    while not ready_to_proceed:\n",
    "        user_input = input(\"Are you happy with the plan? (y/n):\\n\")\n",
    "        if user_input == \"y\":\n",
    "            ready_to_proceed = True\n",
    "        else:\n",
    "            user_input = input(\"Any additional guidance for the planner?:\\n\")\n",
    "            constraints.append(user_input)\n",
    "            plan = portia.plan(task())\n",
    "            print(\"\\nHere are the updated steps in the plan:\")\n",
    "            [print(step.model_dump_json(indent=2)) for step in plan.steps]\n",
    "\n",
    "    # Execute the plan\n",
    "    print(\"\\nThe plan will now be executed. Please wait...\")\n",
    "    run = portia.run_plan(plan)\n",
    "    \n",
    "    if run.state != PlanRunState.COMPLETE:\n",
    "        raise Exception(\n",
    "            f\"Plan run failed with state {run.state}. Check logs for details.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RAI(topic, video_preference = False, number_of_papers = 1):\n",
    "\n",
    "    my_config = Config.from_default()\n",
    "    complete_tool_registry = PortiaToolRegistry(my_config) + custom_tool_registry\n",
    "\n",
    "    portia = Portia(config = my_config,\n",
    "                tools = complete_tool_registry,\n",
    "                execution_hooks=CLIExecutionHooks(),)\n",
    "\n",
    "    constraints = []\n",
    "    # # topic = input(\"What topic are you interested in covering today?\")\n",
    "    # # number_of_papers = int(input(\"How many papers do you want to download?\"))\n",
    "    # topic = \"Using LLMs for Interior Design\"\n",
    "    # number_of_papers = 1\n",
    "    # video_preference = False\n",
    "    # number_of_videos = 2\n",
    "    # podcast_preference = True\n",
    "\n",
    "    task = (\n",
    "                lambda : f\"\"\"You are a research assistant running these tasks: \n",
    "                          - Find and download {number_of_papers} paper{'s' * (number_of_papers > 1)} on the topic of {topic} using the ArXivTool. \n",
    "                          - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
    "                          - From the full text, extract the core mathematical and scientific concepts required \n",
    "                            to understand the paper. Focus only on generalizable topics that could be included \n",
    "                            in a learning pathway or curriculum—avoid content specific to the study's location, \n",
    "                            data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
    "                          - Then use the TopicSelectorTool on these topics. \n",
    "                          - Then use the Notion Tool to create Notion pages for these topics.\n",
    "                          - {video_preference * \"Use the YouTubeTool to find videos on each topic.\"}\n",
    "\n",
    "                            Take into account these constraints: {constraints}\n",
    "                          \"\"\"\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "    # Iterate on the plan with the user until they are happy with it\n",
    "    with execution_context(end_user_id=\"learning_enthusiast\",):\n",
    "        plan = portia.plan(task())\n",
    "        print(\"\\nHere are the steps in the generated plan:\")\n",
    "        [print(step.model_dump_json(indent=2)) for step in plan.steps]\n",
    "        ready_to_proceed = False\n",
    "        while not ready_to_proceed:\n",
    "            user_input = input(\"Are you happy with the plan? (y/n):\\n\")\n",
    "            if user_input == \"y\":\n",
    "                ready_to_proceed = True\n",
    "            else:\n",
    "                user_input = input(\"Any additional guidance for the planner?:\\n\")\n",
    "                constraints.append(user_input)\n",
    "                plan = portia.plan(task())\n",
    "                print(\"\\nHere are the updated steps in the plan:\")\n",
    "                [print(step.model_dump_json(indent=2)) for step in plan.steps]\n",
    "\n",
    "        # Execute the plan\n",
    "        print(\"\\nThe plan will now be executed. Please wait...\")\n",
    "        run = portia.run_plan(plan)\n",
    "\n",
    "        if run.state != PlanRunState.COMPLETE:\n",
    "            raise Exception(\n",
    "                f\"Plan run failed with state {run.state}. Check logs for details.\"\n",
    "            )\n",
    "        \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 20:41:23.616\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running these tasks: \n",
      "                          - Find and download 1 paper on the topic of Using LLMs for Interior Design using the ArXivTool. \n",
      "                          - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
      "                          - From the full text, extract the core mathematical and scientific concepts required \n",
      "                            to understand the paper. Focus only on generalizable topics that could be included \n",
      "                            in a learning pathway or curriculum—avoid content specific to the study's location, \n",
      "                            data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                          - Then use the TopicSelectorTool on these topics. \n",
      "                          - Then use the Notion Tool to create Notion pages for these topics.\n",
      "                          - \n",
      "\n",
      "                            Take into account these constraints: []\n",
      "                          \u001b[0m\n",
      "\u001b[32m2025-04-12 20:41:37.400\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m222\u001b[0m - \u001b[1mPlan created with 6 steps\u001b[0m | {'plan': 'plan-0dd27928-62ee-4ce4-a64a-e2c3cbc71c08'}\n",
      "\n",
      "Here are the steps in the generated plan:\n",
      "{\n",
      "  \"task\": \"Use the arXiv tool to find one paper on the topic 'Using LLMs for Interior Design'. Ensure that the query includes the topic exactly as provided in the query.\",\n",
      "  \"inputs\": [],\n",
      "  \"tool_id\": \"arxiv_tool\",\n",
      "  \"output\": \"$paper_info\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Download the paper using the paper information obtained from the previous step. Provide the paper details as received from the arXiv tool output.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$paper_info\",\n",
      "      \"description\": \"Paper information from arXiv tool output.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"download_tool\",\n",
      "  \"output\": \"$downloaded_papers\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Extract the full text from the PDFs present in the local 'papers' folder by running the PDF reader tool.\",\n",
      "  \"inputs\": [],\n",
      "  \"tool_id\": \"pdf_reader_tool\",\n",
      "  \"output\": \"$extracted_text\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"From the full text extracted in the previous step, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be used in a learning pathway, and list only the overarching topics without explanations or extra text.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$extracted_text\",\n",
      "      \"description\": \"The full text extracted from the downloaded PDFs.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"llm_tool\",\n",
      "  \"output\": \"$extracted_concepts\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Use the topic selector tool to prompt the selection of topics from the list of extracted core concepts. The input must include the list of topics without extra context.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$extracted_concepts\",\n",
      "      \"description\": \"The list of core topics extracted from the full text.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"topic_selector_tool\",\n",
      "  \"output\": \"$selected_topics\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Create Notion pages for each of the selected topics using the Notion tool. Include the topics exactly as provided by the topic selector output.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$selected_topics\",\n",
      "      \"description\": \"List of topics selected from the topic selector tool.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"notion_tool\",\n",
      "  \"output\": \"$notion_pages_created\",\n",
      "  \"condition\": null\n",
      "}\n",
      "\u001b[32m2025-04-12 20:42:05.770\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running these tasks: \n",
      "                          - Find and download 1 paper on the topic of Using LLMs for Interior Design using the ArXivTool. \n",
      "                          - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
      "                          - From the full text, extract the core mathematical and scientific concepts required \n",
      "                            to understand the paper. Focus only on generalizable topics that could be included \n",
      "                            in a learning pathway or curriculum—avoid content specific to the study's location, \n",
      "                            data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                          - Then use the TopicSelectorTool on these topics. \n",
      "                          - Then use the Notion Tool to create Notion pages for these topics.\n",
      "                          - \n",
      "\n",
      "                            Take into account these constraints: ['']\n",
      "                          \u001b[0m\n",
      "\u001b[32m2025-04-12 20:42:20.546\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m222\u001b[0m - \u001b[1mPlan created with 6 steps\u001b[0m | {'plan': 'plan-4b2f877b-dd53-42b2-a0ec-4058652b1ca2'}\n",
      "\n",
      "Here are the updated steps in the plan:\n",
      "{\n",
      "  \"task\": \"Find 1 paper on the topic of Using LLMs for Interior Design using the topic provided in the query.\",\n",
      "  \"inputs\": [],\n",
      "  \"tool_id\": \"arxiv_tool\",\n",
      "  \"output\": \"$arxiv_papers\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Download the paper using the details from the previous step.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$arxiv_papers\",\n",
      "      \"description\": \"The list of paper details obtained from the ArxivTool.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"download_tool\",\n",
      "  \"output\": \"$downloaded_papers\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Run the PDFReaderTool to extract the full text from the PDFs in the local 'papers' folder.\",\n",
      "  \"inputs\": [],\n",
      "  \"tool_id\": \"pdf_reader_tool\",\n",
      "  \"output\": \"$full_text\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Extract the core mathematical and scientific concepts required to understand the paper from the full text. Focus on generalizable topics for a learning pathway and list only the overarching topics without extra explanations or content specific details.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$full_text\",\n",
      "      \"description\": \"The full text extracted from the downloaded PDFs.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"llm_tool\",\n",
      "  \"output\": \"$extracted_topics\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Prompt the user with the list of extracted topics for selection using the topics list.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$extracted_topics\",\n",
      "      \"description\": \"The list of core concepts extracted from the paper's full text.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"topic_selector_tool\",\n",
      "  \"output\": \"$selected_topics\",\n",
      "  \"condition\": null\n",
      "}\n",
      "{\n",
      "  \"task\": \"Create Notion pages for the topics selected by the user.\",\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"name\": \"$selected_topics\",\n",
      "      \"description\": \"The list of topics selected from the user prompt.\"\n",
      "    }\n",
      "  ],\n",
      "  \"tool_id\": \"notion_tool\",\n",
      "  \"output\": \"$notion_pages\",\n",
      "  \"condition\": null\n",
      "}\n",
      "\u001b[32m2025-04-12 20:42:47.136\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running these tasks: \n",
      "                          - Find and download 1 paper on the topic of Using LLMs for Interior Design using the ArXivTool. \n",
      "                          - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
      "                          - From the full text, extract the core mathematical and scientific concepts required \n",
      "                            to understand the paper. Focus only on generalizable topics that could be included \n",
      "                            in a learning pathway or curriculum—avoid content specific to the study's location, \n",
      "                            data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                          - Then use the TopicSelectorTool on these topics. \n",
      "                          - Then use the Notion Tool to create Notion pages for these topics.\n",
      "                          - \n",
      "\n",
      "                            Take into account these constraints: ['', '']\n",
      "                          \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run_RAI(topic=\"Using LLMs for Interior Design\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner(topic, constraints, further_reading = False, youtube_videos = False):\n",
    "    if constraints is None:\n",
    "        constraints = []\n",
    "    \n",
    "    my_config = Config.from_default()\n",
    "    complete_tool_registry = PortiaToolRegistry(my_config) + custom_tool_registry\n",
    "\n",
    "    portia = Portia(config = my_config,\n",
    "                  tools = complete_tool_registry,\n",
    "                  execution_hooks=CLIExecutionHooks(),)\n",
    "\n",
    "    task = (\n",
    "            lambda : f\"\"\"You are a research assistant running these tasks: \n",
    "                      - Find and download a paper on the topic of {topic} using the ArXivTool. \n",
    "                      - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
    "                      - From the full text, extract the core mathematical and scientific concepts required \n",
    "                        to understand the paper. Focus only on generalizable topics that could be included \n",
    "                        in a learning pathway or curriculum—avoid content specific to the study's location, \n",
    "                        data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
    "                      - Then use the TopicSelectorTool on these topics. \n",
    "                      - Then use the Notion Tool to create Notion pages for these topics.\n",
    "                      - {youtube_videos * \"Use the YouTubeTool to find videos on each topic.\"}\n",
    "                      - {further_reading * \"Use the RecReadTool to find resources on each topic.\"}\n",
    "                      \n",
    "                        Take into account these constraints: {constraints}\n",
    "                      \"\"\"\n",
    "\n",
    "        )\n",
    "    \n",
    "    with execution_context(end_user_id=\"learning_enthusiast\"):\n",
    "        plan = portia.plan(task())\n",
    "        steps = [step.model_dump_json(indent=2) for step in plan.steps]\n",
    "        \n",
    "        return plan, steps, task, portia  \n",
    "  \n",
    "\n",
    "def run_RAI(task_lambda, portia):\n",
    "    with execution_context(end_user_id=\"learning_enthusiast\"):\n",
    "        plan = portia.plan(task_lambda())\n",
    "        run = portia.run_plan(plan)\n",
    "        \n",
    "\n",
    "        if run.state != PlanRunState.COMPLETE:\n",
    "            return f\"Plan failed with state {run.state}\"\n",
    "        \n",
    "        return run\n",
    "        #return \"\\n\".join([step.model_dump_json(indent=2) for step in run.step_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 22:41:55.984\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running these tasks: \n",
      "                      - Find and download a paper on the topic of time series using the ArXivTool. \n",
      "                      - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
      "                      - From the full text, extract the core mathematical and scientific concepts required \n",
      "                        to understand the paper. Focus only on generalizable topics that could be included \n",
      "                        in a learning pathway or curriculum—avoid content specific to the study's location, \n",
      "                        data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                      - Then use the TopicSelectorTool on these topics. \n",
      "                      - Then use the Notion Tool to create Notion pages for these topics.\n",
      "                      - \n",
      "                      - \n",
      "                      \n",
      "                        Take into account these constraints: []\n",
      "                      \u001b[0m\n",
      "\u001b[32m2025-04-12 22:42:12.935\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m222\u001b[0m - \u001b[1mPlan created with 6 steps\u001b[0m | {'plan': 'plan-507b88e8-c937-48b2-b082-9f7a8ca75066'}\n",
      "\u001b[32m2025-04-12 22:42:12.935\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running these tasks: \n",
      "                      - Find and download a paper on the topic of time series using the ArXivTool. \n",
      "                      - Run the PDFReaderTool to extract the full text from the pdfs in the local folder.\n",
      "                      - From the full text, extract the core mathematical and scientific concepts required \n",
      "                        to understand the paper. Focus only on generalizable topics that could be included \n",
      "                        in a learning pathway or curriculum—avoid content specific to the study's location, \n",
      "                        data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                      - Then use the TopicSelectorTool on these topics. \n",
      "                      - Then use the Notion Tool to create Notion pages for these topics.\n",
      "                      - \n",
      "                      - \n",
      "                      \n",
      "                        Take into account these constraints: []\n",
      "                      \u001b[0m\n",
      "\u001b[32m2025-04-12 22:42:28.716\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m222\u001b[0m - \u001b[1mPlan created with 6 steps\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10'}\n",
      "\u001b[32m2025-04-12 22:42:33.739\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m528\u001b[0m - \u001b[1mPlan Run State is updated to PlanRunState.IN_PROGRESS. View in your Portia AI dashboard: https://app.portialabs.ai/dashboard/plan-runs?plan_run_id=prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066\u001b[0m\n",
      "\u001b[32m2025-04-12 22:42:33.739\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 0: Using the arXiv tool, search for relevant papers on the topic 'time series'.\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10', 'plan_run': 'prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066'}\n",
      "\u001b[32m2025-04-12 22:42:38.770\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking arXiv Tool with args: {'topic': 'time series', 'max_results': 3}\u001b[0m\n",
      "\u001b[32m2025-04-12 22:42:43.459\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [{\"title\": \"Volatility of Linear and Nonlinear Time Series\", \"summary\": \"Previous studies indicate that nonlinear properties of Gaussian time series\\nwith long-range correlations, $u_i$, can be detected and quantified by studying\\nthe correlations in the magnitude series $|u_i|$, i.e., the ``volatility''.\\nHowever, the origin for this empirical observation still remains unclear, and\\nthe exact relation between the correlations in $u_i$ and the correlations in\\n$|u_i|$ is still unknown. Here we find analytical relations between the scaling\\nexponent of linear series $u_i$ and its magnitude series $|u_i|$. Moreover, we\\nfind that nonlinear time series exhibit stronger (or the same) correlations in\\nthe magnitude time series compared to linear time series with the same\\ntwo-point correlations. Based on these results we propose a simple model that\\ngenerates multifractal time series by explicitly inserting long range\\ncorrelations in the magnitude series; the nonlinear multifractal time series is\\ngenerated by multiplying a long-range correlated time series (that represents\\nthe magnitude series) with uncorrelated time series [that represents the sign\\nseries $sgn(u_i)$]. Our results of magnitude series correlations may help to\\nidentify linear and nonlinear processes in experimental records.\", \"link\": \"https://arxiv.org/pdf/0406310v1.pdf\"}, {\"title\": \"Kolmogorov Space in Time Series Data\", \"summary\": \"We provide the proof that the space of time series data is a Kolmogorov space\\nwith $T_{0}$-separation axiom using the loop space of time series data. In our\\napproach we define a cyclic coordinate of intrinsic time scale of time series\\ndata after empirical mode decomposition. A spinor field of time series data\\ncomes from the rotation of data around price and time axis by defining a new\\nextradimension to time series data. We show that there exist hidden eight\\ndimensions in Kolmogorov space for time series data. Our concept is realized as\\nthe algorithm of empirical mode decomposition and intrinsic time scale\\ndecomposition and it is subsequently used for preliminary analysis on the real\\ntime series data.\", \"link\": \"https://arxiv.org/pdf/1606.03901v1.pdf\"}, {\"title\": \"Ultra-Fast Shapelets for Time Series Classification\", \"summary\": \"Time series shapelets are discriminative subsequences and their similarity to\\na time series can be used for time series classification. Since the discovery\\nof time series shapelets is costly in terms of time, the applicability on long\\nor multivariate time series is difficult. In this work we propose Ultra-Fast\\nShapelets that uses a number of random shapelets. It is shown that Ultra-Fast\\nShapelets yield the same prediction quality as current state-of-the-art\\nshapelet-based time series classifiers that carefully select the shapelets by\\nbeing by up to three orders of magnitudes. Since this method allows a\\nultra-fast shapelet discovery, using shapelets for long multivariate time\\nseries classification becomes feasible.\\n  A method for using shapelets for multivariate time series is proposed and\\nUltra-Fast Shapelets is proven to be successful in comparison to\\nstate-of-the-art multivariate time series classifiers on 15 multivariate time\\nseries datasets from various domains. Finally, time series derivatives that\\nhave proven to be useful for other time series classifiers are investigated for\\nthe shapelet-based classifiers. It is shown that they have a positive impact\\nand that they are easy to integrate with a simple preprocessing step, without\\nthe need of adapting the shapelet discovery algorithm.\", \"link\": \"https://arxiv.org/pdf/1503.05018v1.pdf\"}]\u001b[0m\n",
      "\u001b[32m2025-04-12 22:42:44.917\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 1: Download the paper(s) found by using the download tool with the list of papers from the previous step.\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10', 'plan_run': 'prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066'}\n",
      "\u001b[32m2025-04-12 22:43:01.076\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - Error: 1 validation error for DownloadPaperSchema\n",
      "papers\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\u001b[0m\n",
      "\u001b[32m2025-04-12 22:43:02.499\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 2: Run the PDF reader tool to extract the full text from all PDFs in the local 'papers' folder.\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10', 'plan_run': 'prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066'}\n",
      "\u001b[32m2025-04-12 22:43:06.807\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking PDF reader tool with args: {}\u001b[0m\n",
      "\u001b[32m2025-04-12 22:43:09.899\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - {\"Poster.pdf\": \"--- Page 1 ---\\nForecasting coronavirus in Italy with SIRD modelling\\nGabrielle Littlefair\\nOral: https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d1f1304-438b-40e3-b586-abd7011a8903\\nObjectives\\n• Find estimates for the contact, death and recovery rates\\nof coronavirus in Italy using least squares regression.\\n• Identify any issues with the model and data.\\n• Extrapolate the model to see how coronavirus may\\nprogress in the upcoming months.\\nIntroduction\\nThe ﬁrst case of coronavirus in Italy was reported on the 31st\\nJanuary 2020. Between then and the 6th June 2020, 33,846\\npeople died and the total number of cases rose to 234,801 [8].\\n23.3% of Italy’s population is over the age of 65 [5], making it\\nthe second oldest population in the world. This may explain\\nwhy Italy seems especially vulnerable. I have modelled Italy’s\\noutbreak using SIRD modelling. Modelling accurate rates of\\ninfection, recovery and death, along with the basic reproduc-\\ntion number, R0, can be quite challenging due to the high\\nproportion of infections that are undetected. The number of\\ninfections has been estimated to be as high as 63 times as large\\nas the number recorded [3].\\nSIRD Modelling\\nSIRD modelling is based on four diﬀerent groups within the\\npopulation: those who are susceptible (S); those who are in-\\nfected (I); those who have recovered (R); and those who have\\ndied (D).\\nThe governing equations of my model are as follows:\\nS + I\\nβ\\n−→2I\\nI\\nγ\\n−→R\\nI\\nδ\\n−→D\\nWhere β is the contact rate, γ is the rate of recovery, and δ is\\nthe rate of death. From these equations, the following system\\nof ODEs can be found and solved [6]:\\ndS\\ndt = −β\\nNSI\\ndI\\ndt = β\\nNSI −(γ + δ)I\\ndR\\ndt = γI\\ndD\\ndt = δI\\nFitting the Model to the Data\\nI used least squares regression from python’s lmﬁt module to\\nﬁt my SIRD model to my data [7]. I began by assuming that\\nmy rates β, γ and δ were all constant. However, after plotting\\nthe results of this model, I quickly realised that my value of β\\nneeded to decrease with time. Therefore, I decided to deﬁne\\nβ(t) as a function instead. I found this function intuitively\\nusing a negative exponential model multiplied by the β value\\nfound. I also assumed that the initial number of susceptible in\\nItaly was equal to the population: 60,461,828 [1]. The results\\nfor recovery and death rates were as follows:\\nγ = 0.0234\\nδ = 0.0064\\nThe following values of β correspond to the start of the data\\nand the end of lockdown:\\n18/02/2020\\nβ = 0.1473\\n14/05/2020\\nβ = 0.0080\\nFrom these values of β we can see that at the end of lockdown,\\nthe infection rate was much lower, as expected, due to much\\nfewer contacts between those in the susceptible group and those\\nin the infected group.\\nR0\\nAn important feature of modelling epidemics is the basic repro-\\nduction number R0. This number is the number of secondary\\ninfections resulting from a single primary infection. The reason\\nthis value is so important is that it is an indication of whether\\nthe disease will die out (R0 \\< 1), or if it will become an en-\\ndemic (R0 \\> 1) [4]. This value changes when measures are\\nimplemented that reduce the rate of infection, like lockdown.\\nR0 can be found using the following equation [7]:\\nR0 = β(t)\\nγ\\nUsing my model, I have found values of R0 at diﬀerent times:\\n18/02/2020\\nR0 = 6.2929\\n22/04/2020\\nR0 = 1.0052\\n23/04/2020\\nR0 = 0.9542\\n14/05/2020\\nR0 = 0.3405\\nR0 is ﬁrst below 1, meaning that the disease has begun dying\\nout, on the 23rd April 2020, in the middle of the lockdown pe-\\nriod. This suggests that lockdown was eﬀective. When Italy\\nbegan relaxing its lockdown measures, R0 was very small, how-\\never as the lockdown eases and contact rates increase that value\\ncould easily rise once again.\\nAssumptions\\nSIRD modelling has many drawbacks. First of all, the assumes that once you have been infected you are then immune to the virus,\\nwhich has not been proved or disproved for coronavirus yet. If this assumption is proved wrong, the model would be unreliable\\nuntil another category is added in. My model assumes that you become infectious when you become infected (i.e. when you test\\npositive), however, according to Harvard Medical School [2], you actually become infectious up to 72 hours before you show any\\nsymptoms. Another assumption is that there are no births in the population. There are also problems with the accuracy and\\nreliability of the data [8] being used. Many cases of coronavirus go unreported and untested. There could also be a high proportion\\nof asymptomatic cases [3], which will also remain unrecorded.\\nThe Model\\nFigure 1:Data vs Model plotted between 18/02/2020 and 07/06/2020\\nForecast\\nFigure 2:Model plotted between 18/02/2020 and 06/08/2020\\nConclusion\\nAlthough I do not believe that the model I have gener-\\nated is very accurate, it seems that Italy is very much on\\nthe way towards eradicating coronavirus. However, the un-\\nknown proportion of the population that has coronavirus\\nand is asymptomatic, along with the unrecorded cases,\\ncould mean that we may begin to see an upward trend\\nin the number of cases. Potentially even a second peak.\\nGoing forward, I would like to add in more compartments\\ninto my model (such as the exposed compartment), in order\\nto increase the accuracy of the model. This exposed cate-\\ngory would remove the need for a dampener on the rate of\\ninfection, as a contact rate would then also be estimated,\\nmaking a much more reliable model. I would also like to\\ncompare various countries which have now left lockdown\\nin order to see how exiting the lockdown has aﬀected their\\ninfection rates and whether a second spike seems likely.\\nReferences\\n[1] “Our world in data coronavirus.” [Online]. Available:\\nhttps://ourworldindata.org/coronavirus\\n[2] “Harvard health coronavirus.” [Online]. Available:\\nhttps://www.health.harvard.edu/diseases-and-conditions/\\nif-youve-been-exposed-to-the-coronavirus\\n[3] G. C. Calaﬁore, C. Novara, and C. Possieri, “A modiﬁed sir model for\\nthe covid-19 contagion in italy,” Mar 31, 2020. [Online]. Available:\\n[4] K. Nixon and L. Servitje, Endemic.\\nLondon: Palgrave Macmillan\\nLimited, 2016. [Online]. Available: https://ebookcentral.proquest.\\ncom/lib/[SITE_ID]/detail.action?docID=4720003\\n[5] J. B. Dowd, L. Andriano, D. M. Brazel, V. Rotondi, P. Block,\\nX. Ding, Y. Liu, and M. C. Mills, “Demographic science aids in\\nunderstanding the spread and fatality rates of covid-19,” Proceedings\\nof the National Academy of Sciences of the United States of\\nAmerica, vol. 117, no. 18, pp. 9696–9698, May 5, 2020. [Online].\\nAvailable: https://www.ncbi.nlm.nih.gov/pubmed/32300018\\n[6] . K. S. E. Model, “Introduction to epidemic modeling.”\\n[7] J. Fernández-Villaverde, “Estimating and simulating a sird model of\\ncovid-19 for many countries, states, and cities,” 2020. [Online].\\nAvailable: http://www.econis.eu/PPNSET?PPN=1698547927\\n[8] “John hopkins university coronavirus data.” [Online]. Available:\\nhttps://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\"}\u001b[0m\n",
      "\u001b[32m2025-04-12 22:43:11.535\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 3: Extract the core mathematical and scientific concepts from the full text provided, focusing only on generalizable topics for a learning pathway. List only the overarching topics with no extra explanations.\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10', 'plan_run': 'prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066'}\n",
      "\u001b[32m2025-04-12 22:43:17.078\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking LLM Tool with args: {'task': 'Extract the core mathematical and scientific concepts from the full text provided, focusing only on generalizable topics for a learning pathway. List only the overarching topics with no extra explanations.'}\u001b[0m\n",
      "\u001b[32m2025-04-12 22:43:22.780\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - 1. SIRD Modelling\n",
      "2. Least Squares Regression\n",
      "3. Ordinary Differential Equations (ODEs)\n",
      "4. Basic Reproduction Number (R0)\n",
      "5. Exponential Functions\n",
      "6. Epidemiological Modelling Assumptions\u001b[0m\n",
      "\u001b[32m2025-04-12 22:43:24.437\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 4: Use the topic selector tool to prompt selection from the list of extracted topics.\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10', 'plan_run': 'prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066'}\n",
      "\u001b[32m2025-04-12 22:43:30.185\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking Topic Selector Tool with args: {'raw_topics': ['1. SIRD Modelling', '2. Least Squares Regression', '3. Ordinary Differential Equations (ODEs)', '4. Basic Reproduction Number (R0)', '5. Exponential Functions', '6. Epidemiological Modelling Assumptions']}\u001b[0m\n",
      "\n",
      "📚 Please choose one or more topics to learn about:\n",
      "1. SIRD Modelling\n",
      "2. Least Squares Regression\n",
      "3. Ordinary Differential Equations (ODEs)\n",
      "4. Basic Reproduction Number (R0)\n",
      "5. Exponential Functions\n",
      "6. Epidemiological Modelling Assumptions\n",
      "\u001b[32m2025-04-12 22:44:47.370\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [\"SIRD Modelling\"]\u001b[0m\n",
      "\u001b[32m2025-04-12 22:44:48.804\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 5: Use the Notion tool to create pages for the selected topics.\u001b[0m | {'plan': 'plan-417b4c9e-05ea-441f-b991-7fbf20181a10', 'plan_run': 'prun-fbba3109-ab07-422f-bf96-ee6b2cdbf066'}\n",
      "\u001b[32m2025-04-12 22:44:53.720\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking Notion Tool with args: {'topics': ['SIRD Modelling']}\u001b[0m\n",
      "\u001b[32m2025-04-12 22:45:09.279\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [{\"topic\": \"SIRD Modelling\", \"page_id\": \"1d3573e9-d54c-8179-94ae-effe9f384fbf\"}]\u001b[0m\n",
      "\u001b[32m2025-04-12 22:45:16.045\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[37mportia.portia\u001b[0m:\u001b[37m_log_final_output\u001b[0m:\u001b[37m618\u001b[0m - \u001b[1mFinal output: The research assistant's tasks involved finding and downloading a paper on time series, extracting its full text, and identifying core mathematical and scientific concepts. Despite an error in downloading, the PDFReaderTool extracted text from a local file on SIRD modeling for COVID-19 in Italy. Key concepts identified included SIRD Modelling, Least Squares Regression, ODEs, Basic Reproduction Number, Exponential Functions, and Epidemiological Modelling Assumptions. The TopicSelectorTool highlighted 'SIRD Modelling,' and a Notion page was created for it.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PlanRun(id=PlanRunUUID(uuid=UUID('fbba3109-ab07-422f-bf96-ee6b2cdbf066')), plan_id=PlanUUID(uuid=UUID('417b4c9e-05ea-441f-b991-7fbf20181a10')), current_step_index=5, state=<PlanRunState.COMPLETE: 'COMPLETE'>, execution_context=ExecutionContext(end_user_id='learning_enthusiast', additional_data={}, planning_agent_system_context_extension=None, execution_agent_system_context_extension=None, plan_run_context='Additional context: You MUST use this information to complete your task.\\nInputs: the original inputs provided by the planning_agent\\ninput_name: $selected_topics\\ninput_value: [\\'SIRD Modelling\\']\\ninput_description: List of selected topics\\n----------\\nBroader context: This may be useful information from previous steps that can indirectly help you.\\noutput_name: $paper_list\\noutput_value: [{\\'title\\': \\'Volatility of Linear and Nonlinear Time Series\\', \\'summary\\': \"Previous studies indicate that nonlinear properties of Gaussian time series\\\\nwith long-range correlations, $u_i$, can be detected and quantified by studying\\\\nthe correlations in the magnitude series $|u_i|$, i.e., the ``volatility\\'\\'.\\\\nHowever, the origin for this empirical observation still remains unclear, and\\\\nthe exact relation between the correlations in $u_i$ and the correlations in\\\\n$|u_i|$ is still unknown. Here we find analytical relations between the scaling\\\\nexponent of linear series $u_i$ and its magnitude series $|u_i|$. Moreover, we\\\\nfind that nonlinear time series exhibit stronger (or the same) correlations in\\\\nthe magnitude time series compared to linear time series with the same\\\\ntwo-point correlations. Based on these results we propose a simple model that\\\\ngenerates multifractal time series by explicitly inserting long range\\\\ncorrelations in the magnitude series; the nonlinear multifractal time series is\\\\ngenerated by multiplying a long-range correlated time series (that represents\\\\nthe magnitude series) with uncorrelated time series [that represents the sign\\\\nseries $sgn(u_i)$]. Our results of magnitude series correlations may help to\\\\nidentify linear and nonlinear processes in experimental records.\", \\'link\\': \\'https://arxiv.org/pdf/0406310v1.pdf\\'}, {\\'title\\': \\'Kolmogorov Space in Time Series Data\\', \\'summary\\': \\'We provide the proof that the space of time series data is a Kolmogorov space\\\\nwith $T_{0}$-separation axiom using the loop space of time series data. In our\\\\napproach we define a cyclic coordinate of intrinsic time scale of time series\\\\ndata after empirical mode decomposition. A spinor field of time series data\\\\ncomes from the rotation of data around price and time axis by defining a new\\\\nextradimension to time series data. We show that there exist hidden eight\\\\ndimensions in Kolmogorov space for time series data. Our concept is realized as\\\\nthe algorithm of empirical mode decomposition and intrinsic time scale\\\\ndecomposition and it is subsequently used for preliminary analysis on the real\\\\ntime series data.\\', \\'link\\': \\'https://arxiv.org/pdf/1606.03901v1.pdf\\'}, {\\'title\\': \\'Ultra-Fast Shapelets for Time Series Classification\\', \\'summary\\': \\'Time series shapelets are discriminative subsequences and their similarity to\\\\na time series can be used for time series classification. Since the discovery\\\\nof time series shapelets is costly in terms of time, the applicability on long\\\\nor multivariate time series is difficult. In this work we propose Ultra-Fast\\\\nShapelets that uses a number of random shapelets. It is shown that Ultra-Fast\\\\nShapelets yield the same prediction quality as current state-of-the-art\\\\nshapelet-based time series classifiers that carefully select the shapelets by\\\\nbeing by up to three orders of magnitudes. Since this method allows a\\\\nultra-fast shapelet discovery, using shapelets for long multivariate time\\\\nseries classification becomes feasible.\\\\n  A method for using shapelets for multivariate time series is proposed and\\\\nUltra-Fast Shapelets is proven to be successful in comparison to\\\\nstate-of-the-art multivariate time series classifiers on 15 multivariate time\\\\nseries datasets from various domains. Finally, time series derivatives that\\\\nhave proven to be useful for other time series classifiers are investigated for\\\\nthe shapelet-based classifiers. It is shown that they have a positive impact\\\\nand that they are easy to integrate with a simple preprocessing step, without\\\\nthe need of adapting the shapelet discovery algorithm.\\', \\'link\\': \\'https://arxiv.org/pdf/1503.05018v1.pdf\\'}]\\n----------\\noutput_name: $extracted_topics\\noutput_value: 1. SIRD Modelling\\n2. Least Squares Regression\\n3. Ordinary Differential Equations (ODEs)\\n4. Basic Reproduction Number (R0)\\n5. Exponential Functions\\n6. Epidemiological Modelling Assumptions\\n----------\\noutput_name: $full_text\\noutput_value: {\\'Poster.pdf\\': \\'--- Page 1 ---\\\\nForecasting coronavirus in Italy with SIRD modelling\\\\nGabrielle Littlefair\\\\nOral: https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d1f1304-438b-40e3-b586-abd7011a8903\\\\nObjectives\\\\n• Find estimates for the contact, death and recovery rates\\\\nof coronavirus in Italy using least squares regression.\\\\n• Identify any issues with the model and data.\\\\n• Extrapolate the model to see how coronavirus may\\\\nprogress in the upcoming months.\\\\nIntroduction\\\\nThe ﬁrst case of coronavirus in Italy was reported on the 31st\\\\nJanuary 2020. Between then and the 6th June 2020, 33,846\\\\npeople died and the total number of cases rose to 234,801 [8].\\\\n23.3% of Italy’s population is over the age of 65 [5], making it\\\\nthe second oldest population in the world. This may explain\\\\nwhy Italy seems especially vulnerable. I have modelled Italy’s\\\\noutbreak using SIRD modelling. Modelling accurate rates of\\\\ninfection, recovery and death, along with the basic reproduc-\\\\ntion number, R0, can be quite challenging due to the high\\\\nproportion of infections that are undetected. The number of\\\\ninfections has been estimated to be as high as 63 times as large\\\\nas the number recorded [3].\\\\nSIRD Modelling\\\\nSIRD modelling is based on four diﬀerent groups within the\\\\npopulation: those who are susceptible (S); those who are in-\\\\nfected (I); those who have recovered (R); and those who have\\\\ndied (D).\\\\nThe governing equations of my model are as follows:\\\\nS + I\\\\nβ\\\\n−→2I\\\\nI\\\\nγ\\\\n−→R\\\\nI\\\\nδ\\\\n−→D\\\\nWhere β is the contact rate, γ is the rate of recovery, and δ is\\\\nthe rate of death. From these equations, the following system\\\\nof ODEs can be found and solved [6]:\\\\ndS\\\\ndt = −β\\\\nNSI\\\\ndI\\\\ndt = β\\\\nNSI −(γ + δ)I\\\\ndR\\\\ndt = γI\\\\ndD\\\\ndt = δI\\\\nFitting the Model to the Data\\\\nI used least squares regression from python’s lmﬁt module to\\\\nﬁt my SIRD model to my data [7]. I began by assuming that\\\\nmy rates β, γ and δ were all constant. However, after plotting\\\\nthe results of this model, I quickly realised that my value of β\\\\nneeded to decrease with time. Therefore, I decided to deﬁne\\\\nβ(t) as a function instead. I found this function intuitively\\\\nusing a negative exponential model multiplied by the β value\\\\nfound. I also assumed that the initial number of susceptible in\\\\nItaly was equal to the population: 60,461,828 [1]. The results\\\\nfor recovery and death rates were as follows:\\\\nγ = 0.0234\\\\nδ = 0.0064\\\\nThe following values of β correspond to the start of the data\\\\nand the end of lockdown:\\\\n18/02/2020\\\\nβ = 0.1473\\\\n14/05/2020\\\\nβ = 0.0080\\\\nFrom these values of β we can see that at the end of lockdown,\\\\nthe infection rate was much lower, as expected, due to much\\\\nfewer contacts between those in the susceptible group and those\\\\nin the infected group.\\\\nR0\\\\nAn important feature of modelling epidemics is the basic repro-\\\\nduction number R0. This number is the number of secondary\\\\ninfections resulting from a single primary infection. The reason\\\\nthis value is so important is that it is an indication of whether\\\\nthe disease will die out (R0 < 1), or if it will become an en-\\\\ndemic (R0 > 1) [4]. This value changes when measures are\\\\nimplemented that reduce the rate of infection, like lockdown.\\\\nR0 can be found using the following equation [7]:\\\\nR0 = β(t)\\\\nγ\\\\nUsing my model, I have found values of R0 at diﬀerent times:\\\\n18/02/2020\\\\nR0 = 6.2929\\\\n22/04/2020\\\\nR0 = 1.0052\\\\n23/04/2020\\\\nR0 = 0.9542\\\\n14/05/2020\\\\nR0 = 0.3405\\\\nR0 is ﬁrst below 1, meaning that the disease has begun dying\\\\nout, on the 23rd April 2020, in the middle of the lockdown pe-\\\\nriod. This suggests that lockdown was eﬀective. When Italy\\\\nbegan relaxing its lockdown measures, R0 was very small, how-\\\\never as the lockdown eases and contact rates increase that value\\\\ncould easily rise once again.\\\\nAssumptions\\\\nSIRD modelling has many drawbacks. First of all, the assumes that once you have been infected you are then immune to the virus,\\\\nwhich has not been proved or disproved for coronavirus yet. If this assumption is proved wrong, the model would be unreliable\\\\nuntil another category is added in. My model assumes that you become infectious when you become infected (i.e. when you test\\\\npositive), however, according to Harvard Medical School [2], you actually become infectious up to 72 hours before you show any\\\\nsymptoms. Another assumption is that there are no births in the population. There are also problems with the accuracy and\\\\nreliability of the data [8] being used. Many cases of coronavirus go unreported and untested. There could also be a high proportion\\\\nof asymptomatic cases [3], which will also remain unrecorded.\\\\nThe Model\\\\nFigure 1:Data vs Model plotted between 18/02/2020 and 07/06/2020\\\\nForecast\\\\nFigure 2:Model plotted between 18/02/2020 and 06/08/2020\\\\nConclusion\\\\nAlthough I do not believe that the model I have gener-\\\\nated is very accurate, it seems that Italy is very much on\\\\nthe way towards eradicating coronavirus. However, the un-\\\\nknown proportion of the population that has coronavirus\\\\nand is asymptomatic, along with the unrecorded cases,\\\\ncould mean that we may begin to see an upward trend\\\\nin the number of cases. Potentially even a second peak.\\\\nGoing forward, I would like to add in more compartments\\\\ninto my model (such as the exposed compartment), in order\\\\nto increase the accuracy of the model. This exposed cate-\\\\ngory would remove the need for a dampener on the rate of\\\\ninfection, as a contact rate would then also be estimated,\\\\nmaking a much more reliable model. I would also like to\\\\ncompare various countries which have now left lockdown\\\\nin order to see how exiting the lockdown has aﬀected their\\\\ninfection rates and whether a second spike seems likely.\\\\nReferences\\\\n[1] “Our world in data coronavirus.” [Online]. Available:\\\\nhttps://ourworldindata.org/coronavirus\\\\n[2] “Harvard health coronavirus.” [Online]. Available:\\\\nhttps://www.health.harvard.edu/diseases-and-conditions/\\\\nif-youve-been-exposed-to-the-coronavirus\\\\n[3] G. C. Calaﬁore, C. Novara, and C. Possieri, “A modiﬁed sir model for\\\\nthe covid-19 contagion in italy,” Mar 31, 2020. [Online]. Available:\\\\n[4] K. Nixon and L. Servitje, Endemic.\\\\nLondon: Palgrave Macmillan\\\\nLimited, 2016. [Online]. Available: https://ebookcentral.proquest.\\\\ncom/lib/[SITE_ID]/detail.action?docID=4720003\\\\n[5] J. B. Dowd, L. Andriano, D. M. Brazel, V. Rotondi, P. Block,\\\\nX. Ding, Y. Liu, and M. C. Mills, “Demographic science aids in\\\\nunderstanding the spread and fatality rates of covid-19,” Proceedings\\\\nof the National Academy of Sciences of the United States of\\\\nAmerica, vol. 117, no. 18, pp. 9696–9698, May 5, 2020. [Online].\\\\nAvailable: https://www.ncbi.nlm.nih.gov/pubmed/32300018\\\\n[6] . K. S. E. Model, “Introduction to epidemic modeling.”\\\\n[7] J. Fernández-Villaverde, “Estimating and simulating a sird model of\\\\ncovid-19 for many countries, states, and cities,” 2020. [Online].\\\\nAvailable: http://www.econis.eu/PPNSET?PPN=1698547927\\\\n[8] “John hopkins university coronavirus data.” [Online]. Available:\\\\nhttps://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\\'}\\n----------\\noutput_name: $downloaded_papers\\noutput_value: Error: 1 validation error for DownloadPaperSchema\\npapers\\n  Field required [type=missing, input_value={}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\\n Please fix your mistakes.\\n----------\\nMetadata: This section contains general context about this execution.\\nend_user_id: learning_enthusiast\\nSystem Context:\\nToday\\'s date is 2025-04-12'), outputs=PlanRunOutputs(clarifications=[], step_outputs={'$paper_list': LocalOutput(value=[{'title': 'Volatility of Linear and Nonlinear Time Series', 'summary': \"Previous studies indicate that nonlinear properties of Gaussian time series\\nwith long-range correlations, $u_i$, can be detected and quantified by studying\\nthe correlations in the magnitude series $|u_i|$, i.e., the ``volatility''.\\nHowever, the origin for this empirical observation still remains unclear, and\\nthe exact relation between the correlations in $u_i$ and the correlations in\\n$|u_i|$ is still unknown. Here we find analytical relations between the scaling\\nexponent of linear series $u_i$ and its magnitude series $|u_i|$. Moreover, we\\nfind that nonlinear time series exhibit stronger (or the same) correlations in\\nthe magnitude time series compared to linear time series with the same\\ntwo-point correlations. Based on these results we propose a simple model that\\ngenerates multifractal time series by explicitly inserting long range\\ncorrelations in the magnitude series; the nonlinear multifractal time series is\\ngenerated by multiplying a long-range correlated time series (that represents\\nthe magnitude series) with uncorrelated time series [that represents the sign\\nseries $sgn(u_i)$]. Our results of magnitude series correlations may help to\\nidentify linear and nonlinear processes in experimental records.\", 'link': 'https://arxiv.org/pdf/0406310v1.pdf'}, {'title': 'Kolmogorov Space in Time Series Data', 'summary': 'We provide the proof that the space of time series data is a Kolmogorov space\\nwith $T_{0}$-separation axiom using the loop space of time series data. In our\\napproach we define a cyclic coordinate of intrinsic time scale of time series\\ndata after empirical mode decomposition. A spinor field of time series data\\ncomes from the rotation of data around price and time axis by defining a new\\nextradimension to time series data. We show that there exist hidden eight\\ndimensions in Kolmogorov space for time series data. Our concept is realized as\\nthe algorithm of empirical mode decomposition and intrinsic time scale\\ndecomposition and it is subsequently used for preliminary analysis on the real\\ntime series data.', 'link': 'https://arxiv.org/pdf/1606.03901v1.pdf'}, {'title': 'Ultra-Fast Shapelets for Time Series Classification', 'summary': 'Time series shapelets are discriminative subsequences and their similarity to\\na time series can be used for time series classification. Since the discovery\\nof time series shapelets is costly in terms of time, the applicability on long\\nor multivariate time series is difficult. In this work we propose Ultra-Fast\\nShapelets that uses a number of random shapelets. It is shown that Ultra-Fast\\nShapelets yield the same prediction quality as current state-of-the-art\\nshapelet-based time series classifiers that carefully select the shapelets by\\nbeing by up to three orders of magnitudes. Since this method allows a\\nultra-fast shapelet discovery, using shapelets for long multivariate time\\nseries classification becomes feasible.\\n  A method for using shapelets for multivariate time series is proposed and\\nUltra-Fast Shapelets is proven to be successful in comparison to\\nstate-of-the-art multivariate time series classifiers on 15 multivariate time\\nseries datasets from various domains. Finally, time series derivatives that\\nhave proven to be useful for other time series classifiers are investigated for\\nthe shapelet-based classifiers. It is shown that they have a positive impact\\nand that they are easy to integrate with a simple preprocessing step, without\\nthe need of adapting the shapelet discovery algorithm.', 'link': 'https://arxiv.org/pdf/1503.05018v1.pdf'}], summary='[{\"title\": \"Volatility of Linear and Nonlinear Time Series\", \"summary\": \"Previous studies indicate that nonlinear properties of Gaussian time series\\\\nwith long-range correlations, $u_i$, can be detected and quantified by studying\\\\nthe correlations in the magnitude series $|u_i|$, i.e., the ``volatility\\'\\'.\\\\nHowever, the origin for this empirical observation still remains unclear, and\\\\nthe exact relation between the correlations in $u_i$ and the correlations in\\\\n$|u_i|$ is still unknown. Here we find analytical relations between the scaling\\\\nexponent of linear series $u_i$ and its magnitude series $|u_i|$. Moreover, we\\\\nfind that nonlinear time series exhibit stronger (or the same) correlations in\\\\nthe magnitude time series compared to linear time series with the same\\\\ntwo-point correlations. Based on these results we propose a simple model that\\\\ngenerates multifractal time series by explicitly inserting long range\\\\ncorrelations in the magnitude series; the nonlinear multifractal time series is\\\\ngenerated by multiplying a long-range correlated time series (that represents\\\\nthe magnitude series) with uncorrelated time series [that represents the sign\\\\nseries $sgn(u_i)$]. Our results of magnitude series correlations may help to\\\\nidentify linear and nonlinear processes in experimental records.\", \"link\": \"https://arxiv.org/pdf/0406310v1.pdf\"}, {\"title\": \"Kolmogorov Space in Time Series Data\", \"summary\": \"We provide the proof that the space of time series data is a Kolmogorov space\\\\nwith $T_{0}$-separation axiom using the loop space of time series data. In our\\\\napproach we define a cyclic coordinate of intrinsic time scale of time series\\\\ndata after empirical mode decomposition. A spinor field of time series data\\\\ncomes from the rotation of data around price and time axis by defining a new\\\\nextradimension to time series data. We show that there exist hidden eight\\\\ndimensions in Kolmogorov space for time series data. Our concept is realized as\\\\nthe algorithm of empirical mode decomposition and intrinsic time scale\\\\ndecomposition and it is subsequently used for preliminary analysis on the real\\\\ntime series data.\", \"link\": \"https://arxiv.org/pdf/1606.03901v1.pdf\"}, {\"title\": \"Ultra-Fast Shapelets for Time Series Classification\", \"summary\": \"Time series shapelets are discriminative subsequences and their similarity to\\\\na time series can be used for time series classification. Since the discovery\\\\nof time series shapelets is costly in terms of time, the applicability on long\\\\nor multivariate time series is difficult. In this work we propose Ultra-Fast\\\\nShapelets that uses a number of random shapelets. It is shown that Ultra-Fast\\\\nShapelets yield the same prediction quality as current state-of-the-art\\\\nshapelet-based time series classifiers that carefully select the shapelets by\\\\nbeing by up to three orders of magnitudes. Since this method allows a\\\\nultra-fast shapelet discovery, using shapelets for long multivariate time\\\\nseries classification becomes feasible.\\\\n  A method for using shapelets for multivariate time series is proposed and\\\\nUltra-Fast Shapelets is proven to be successful in comparison to\\\\nstate-of-the-art multivariate time series classifiers on 15 multivariate time\\\\nseries datasets from various domains. Finally, time series derivatives that\\\\nhave proven to be useful for other time series classifiers are investigated for\\\\nthe shapelet-based classifiers. It is shown that they have a positive impact\\\\nand that they are easy to integrate with a simple preprocessing step, without\\\\nthe need of adapting the shapelet discovery algorithm.\", \"link\": \"https://arxiv.org/pdf/1503.05018v1.pdf\"}]'), '$downloaded_papers': LocalOutput(value='Error: 1 validation error for DownloadPaperSchema\\npapers\\n  Field required [type=missing, input_value={}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\\n Please fix your mistakes.', summary='Error: 1 validation error for DownloadPaperSchema\\npapers\\n  Field required [type=missing, input_value={}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\\n Please fix your mistakes.'), '$full_text': LocalOutput(value={'Poster.pdf': '--- Page 1 ---\\nForecasting coronavirus in Italy with SIRD modelling\\nGabrielle Littlefair\\nOral: https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d1f1304-438b-40e3-b586-abd7011a8903\\nObjectives\\n• Find estimates for the contact, death and recovery rates\\nof coronavirus in Italy using least squares regression.\\n• Identify any issues with the model and data.\\n• Extrapolate the model to see how coronavirus may\\nprogress in the upcoming months.\\nIntroduction\\nThe ﬁrst case of coronavirus in Italy was reported on the 31st\\nJanuary 2020. Between then and the 6th June 2020, 33,846\\npeople died and the total number of cases rose to 234,801 [8].\\n23.3% of Italy’s population is over the age of 65 [5], making it\\nthe second oldest population in the world. This may explain\\nwhy Italy seems especially vulnerable. I have modelled Italy’s\\noutbreak using SIRD modelling. Modelling accurate rates of\\ninfection, recovery and death, along with the basic reproduc-\\ntion number, R0, can be quite challenging due to the high\\nproportion of infections that are undetected. The number of\\ninfections has been estimated to be as high as 63 times as large\\nas the number recorded [3].\\nSIRD Modelling\\nSIRD modelling is based on four diﬀerent groups within the\\npopulation: those who are susceptible (S); those who are in-\\nfected (I); those who have recovered (R); and those who have\\ndied (D).\\nThe governing equations of my model are as follows:\\nS + I\\nβ\\n−→2I\\nI\\nγ\\n−→R\\nI\\nδ\\n−→D\\nWhere β is the contact rate, γ is the rate of recovery, and δ is\\nthe rate of death. From these equations, the following system\\nof ODEs can be found and solved [6]:\\ndS\\ndt = −β\\nNSI\\ndI\\ndt = β\\nNSI −(γ + δ)I\\ndR\\ndt = γI\\ndD\\ndt = δI\\nFitting the Model to the Data\\nI used least squares regression from python’s lmﬁt module to\\nﬁt my SIRD model to my data [7]. I began by assuming that\\nmy rates β, γ and δ were all constant. However, after plotting\\nthe results of this model, I quickly realised that my value of β\\nneeded to decrease with time. Therefore, I decided to deﬁne\\nβ(t) as a function instead. I found this function intuitively\\nusing a negative exponential model multiplied by the β value\\nfound. I also assumed that the initial number of susceptible in\\nItaly was equal to the population: 60,461,828 [1]. The results\\nfor recovery and death rates were as follows:\\nγ = 0.0234\\nδ = 0.0064\\nThe following values of β correspond to the start of the data\\nand the end of lockdown:\\n18/02/2020\\nβ = 0.1473\\n14/05/2020\\nβ = 0.0080\\nFrom these values of β we can see that at the end of lockdown,\\nthe infection rate was much lower, as expected, due to much\\nfewer contacts between those in the susceptible group and those\\nin the infected group.\\nR0\\nAn important feature of modelling epidemics is the basic repro-\\nduction number R0. This number is the number of secondary\\ninfections resulting from a single primary infection. The reason\\nthis value is so important is that it is an indication of whether\\nthe disease will die out (R0 < 1), or if it will become an en-\\ndemic (R0 > 1) [4]. This value changes when measures are\\nimplemented that reduce the rate of infection, like lockdown.\\nR0 can be found using the following equation [7]:\\nR0 = β(t)\\nγ\\nUsing my model, I have found values of R0 at diﬀerent times:\\n18/02/2020\\nR0 = 6.2929\\n22/04/2020\\nR0 = 1.0052\\n23/04/2020\\nR0 = 0.9542\\n14/05/2020\\nR0 = 0.3405\\nR0 is ﬁrst below 1, meaning that the disease has begun dying\\nout, on the 23rd April 2020, in the middle of the lockdown pe-\\nriod. This suggests that lockdown was eﬀective. When Italy\\nbegan relaxing its lockdown measures, R0 was very small, how-\\never as the lockdown eases and contact rates increase that value\\ncould easily rise once again.\\nAssumptions\\nSIRD modelling has many drawbacks. First of all, the assumes that once you have been infected you are then immune to the virus,\\nwhich has not been proved or disproved for coronavirus yet. If this assumption is proved wrong, the model would be unreliable\\nuntil another category is added in. My model assumes that you become infectious when you become infected (i.e. when you test\\npositive), however, according to Harvard Medical School [2], you actually become infectious up to 72 hours before you show any\\nsymptoms. Another assumption is that there are no births in the population. There are also problems with the accuracy and\\nreliability of the data [8] being used. Many cases of coronavirus go unreported and untested. There could also be a high proportion\\nof asymptomatic cases [3], which will also remain unrecorded.\\nThe Model\\nFigure 1:Data vs Model plotted between 18/02/2020 and 07/06/2020\\nForecast\\nFigure 2:Model plotted between 18/02/2020 and 06/08/2020\\nConclusion\\nAlthough I do not believe that the model I have gener-\\nated is very accurate, it seems that Italy is very much on\\nthe way towards eradicating coronavirus. However, the un-\\nknown proportion of the population that has coronavirus\\nand is asymptomatic, along with the unrecorded cases,\\ncould mean that we may begin to see an upward trend\\nin the number of cases. Potentially even a second peak.\\nGoing forward, I would like to add in more compartments\\ninto my model (such as the exposed compartment), in order\\nto increase the accuracy of the model. This exposed cate-\\ngory would remove the need for a dampener on the rate of\\ninfection, as a contact rate would then also be estimated,\\nmaking a much more reliable model. I would also like to\\ncompare various countries which have now left lockdown\\nin order to see how exiting the lockdown has aﬀected their\\ninfection rates and whether a second spike seems likely.\\nReferences\\n[1] “Our world in data coronavirus.” [Online]. Available:\\nhttps://ourworldindata.org/coronavirus\\n[2] “Harvard health coronavirus.” [Online]. Available:\\nhttps://www.health.harvard.edu/diseases-and-conditions/\\nif-youve-been-exposed-to-the-coronavirus\\n[3] G. C. Calaﬁore, C. Novara, and C. Possieri, “A modiﬁed sir model for\\nthe covid-19 contagion in italy,” Mar 31, 2020. [Online]. Available:\\n[4] K. Nixon and L. Servitje, Endemic.\\nLondon: Palgrave Macmillan\\nLimited, 2016. [Online]. Available: https://ebookcentral.proquest.\\ncom/lib/[SITE_ID]/detail.action?docID=4720003\\n[5] J. B. Dowd, L. Andriano, D. M. Brazel, V. Rotondi, P. Block,\\nX. Ding, Y. Liu, and M. C. Mills, “Demographic science aids in\\nunderstanding the spread and fatality rates of covid-19,” Proceedings\\nof the National Academy of Sciences of the United States of\\nAmerica, vol. 117, no. 18, pp. 9696–9698, May 5, 2020. [Online].\\nAvailable: https://www.ncbi.nlm.nih.gov/pubmed/32300018\\n[6] . K. S. E. Model, “Introduction to epidemic modeling.”\\n[7] J. Fernández-Villaverde, “Estimating and simulating a sird model of\\ncovid-19 for many countries, states, and cities,” 2020. [Online].\\nAvailable: http://www.econis.eu/PPNSET?PPN=1698547927\\n[8] “John hopkins university coronavirus data.” [Online]. Available:\\nhttps://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases'}, summary='{\"Poster.pdf\": \"--- Page 1 ---\\\\nForecasting coronavirus in Italy with SIRD modelling\\\\nGabrielle Littlefair\\\\nOral: https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d1f1304-438b-40e3-b586-abd7011a8903\\\\nObjectives\\\\n• Find estimates for the contact, death and recovery rates\\\\nof coronavirus in Italy using least squares regression.\\\\n• Identify any issues with the model and data.\\\\n• Extrapolate the model to see how coronavirus may\\\\nprogress in the upcoming months.\\\\nIntroduction\\\\nThe ﬁrst case of coronavirus in Italy was reported on the 31st\\\\nJanuary 2020. Between then and the 6th June 2020, 33,846\\\\npeople died and the total number of cases rose to 234,801 [8].\\\\n23.3% of Italy’s population is over the age of 65 [5], making it\\\\nthe second oldest population in the world. This may explain\\\\nwhy Italy seems especially vulnerable. I have modelled Italy’s\\\\noutbreak using SIRD modelling. Modelling accurate rates of\\\\ninfection, recovery and death, along with the basic reproduc-\\\\ntion number, R0, can be quite challenging due to the high\\\\nproportion of infections that are undetected. The number of\\\\ninfections has been estimated to be as high as 63 times as large\\\\nas the number recorded [3].\\\\nSIRD Modelling\\\\nSIRD modelling is based on four diﬀerent groups within the\\\\npopulation: those who are susceptible (S); those who are in-\\\\nfected (I); those who have recovered (R); and those who have\\\\ndied (D).\\\\nThe governing equations of my model are as follows:\\\\nS + I\\\\nβ\\\\n−→2I\\\\nI\\\\nγ\\\\n−→R\\\\nI\\\\nδ\\\\n−→D\\\\nWhere β is the contact rate, γ is the rate of recovery, and δ is\\\\nthe rate of death. From these equations, the following system\\\\nof ODEs can be found and solved [6]:\\\\ndS\\\\ndt = −β\\\\nNSI\\\\ndI\\\\ndt = β\\\\nNSI −(γ + δ)I\\\\ndR\\\\ndt = γI\\\\ndD\\\\ndt = δI\\\\nFitting the Model to the Data\\\\nI used least squares regression from python’s lmﬁt module to\\\\nﬁt my SIRD model to my data [7]. I began by assuming that\\\\nmy rates β, γ and δ were all constant. However, after plotting\\\\nthe results of this model, I quickly realised that my value of β\\\\nneeded to decrease with time. Therefore, I decided to deﬁne\\\\nβ(t) as a function instead. I found this function intuitively\\\\nusing a negative exponential model multiplied by the β value\\\\nfound. I also assumed that the initial number of susceptible in\\\\nItaly was equal to the population: 60,461,828 [1]. The results\\\\nfor recovery and death rates were as follows:\\\\nγ = 0.0234\\\\nδ = 0.0064\\\\nThe following values of β correspond to the start of the data\\\\nand the end of lockdown:\\\\n18/02/2020\\\\nβ = 0.1473\\\\n14/05/2020\\\\nβ = 0.0080\\\\nFrom these values of β we can see that at the end of lockdown,\\\\nthe infection rate was much lower, as expected, due to much\\\\nfewer contacts between those in the susceptible group and those\\\\nin the infected group.\\\\nR0\\\\nAn important feature of modelling epidemics is the basic repro-\\\\nduction number R0. This number is the number of secondary\\\\ninfections resulting from a single primary infection. The reason\\\\nthis value is so important is that it is an indication of whether\\\\nthe disease will die out (R0 < 1), or if it will become an en-\\\\ndemic (R0 > 1) [4]. This value changes when measures are\\\\nimplemented that reduce the rate of infection, like lockdown.\\\\nR0 can be found using the following equation [7]:\\\\nR0 = β(t)\\\\nγ\\\\nUsing my model, I have found values of R0 at diﬀerent times:\\\\n18/02/2020\\\\nR0 = 6.2929\\\\n22/04/2020\\\\nR0 = 1.0052\\\\n23/04/2020\\\\nR0 = 0.9542\\\\n14/05/2020\\\\nR0 = 0.3405\\\\nR0 is ﬁrst below 1, meaning that the disease has begun dying\\\\nout, on the 23rd April 2020, in the middle of the lockdown pe-\\\\nriod. This suggests that lockdown was eﬀective. When Italy\\\\nbegan relaxing its lockdown measures, R0 was very small, how-\\\\never as the lockdown eases and contact rates increase that value\\\\ncould easily rise once again.\\\\nAssumptions\\\\nSIRD modelling has many drawbacks. First of all, the assumes that once you have been infected you are then immune to the virus,\\\\nwhich has not been proved or disproved for coronavirus yet. If this assumption is proved wrong, the model would be unreliable\\\\nuntil another category is added in. My model assumes that you become infectious when you become infected (i.e. when you test\\\\npositive), however, according to Harvard Medical School [2], you actually become infectious up to 72 hours before you show any\\\\nsymptoms. Another assumption is that there are no births in the population. There are also problems with the accuracy and\\\\nreliability of the data [8] being used. Many cases of coronavirus go unreported and untested. There could also be a high proportion\\\\nof asymptomatic cases [3], which will also remain unrecorded.\\\\nThe Model\\\\nFigure 1:Data vs Model plotted between 18/02/2020 and 07/06/2020\\\\nForecast\\\\nFigure 2:Model plotted between 18/02/2020 and 06/08/2020\\\\nConclusion\\\\nAlthough I do not believe that the model I have gener-\\\\nated is very accurate, it seems that Italy is very much on\\\\nthe way towards eradicating coronavirus. However, the un-\\\\nknown proportion of the population that has coronavirus\\\\nand is asymptomatic, along with the unrecorded cases,\\\\ncould mean that we may begin to see an upward trend\\\\nin the number of cases. Potentially even a second peak.\\\\nGoing forward, I would like to add in more compartments\\\\ninto my model (such as the exposed compartment), in order\\\\nto increase the accuracy of the model. This exposed cate-\\\\ngory would remove the need for a dampener on the rate of\\\\ninfection, as a contact rate would then also be estimated,\\\\nmaking a much more reliable model. I would also like to\\\\ncompare various countries which have now left lockdown\\\\nin order to see how exiting the lockdown has aﬀected their\\\\ninfection rates and whether a second spike seems likely.\\\\nReferences\\\\n[1] “Our world in data coronavirus.” [Online]. Available:\\\\nhttps://ourworldindata.org/coronavirus\\\\n[2] “Harvard health coronavirus.” [Online]. Available:\\\\nhttps://www.health.harvard.edu/diseases-and-conditions/\\\\nif-youve-been-exposed-to-the-coronavirus\\\\n[3] G. C. Calaﬁore, C. Novara, and C. Possieri, “A modiﬁed sir model for\\\\nthe covid-19 contagion in italy,” Mar 31, 2020. [Online]. Available:\\\\n[4] K. Nixon and L. Servitje, Endemic.\\\\nLondon: Palgrave Macmillan\\\\nLimited, 2016. [Online]. Available: https://ebookcentral.proquest.\\\\ncom/lib/[SITE_ID]/detail.action?docID=4720003\\\\n[5] J. B. Dowd, L. Andriano, D. M. Brazel, V. Rotondi, P. Block,\\\\nX. Ding, Y. Liu, and M. C. Mills, “Demographic science aids in\\\\nunderstanding the spread and fatality rates of covid-19,” Proceedings\\\\nof the National Academy of Sciences of the United States of\\\\nAmerica, vol. 117, no. 18, pp. 9696–9698, May 5, 2020. [Online].\\\\nAvailable: https://www.ncbi.nlm.nih.gov/pubmed/32300018\\\\n[6] . K. S. E. Model, “Introduction to epidemic modeling.”\\\\n[7] J. Fernández-Villaverde, “Estimating and simulating a sird model of\\\\ncovid-19 for many countries, states, and cities,” 2020. [Online].\\\\nAvailable: http://www.econis.eu/PPNSET?PPN=1698547927\\\\n[8] “John hopkins university coronavirus data.” [Online]. Available:\\\\nhttps://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\"}'), '$extracted_topics': LocalOutput(value='1. SIRD Modelling\\n2. Least Squares Regression\\n3. Ordinary Differential Equations (ODEs)\\n4. Basic Reproduction Number (R0)\\n5. Exponential Functions\\n6. Epidemiological Modelling Assumptions', summary='1. SIRD Modelling\\n2. Least Squares Regression\\n3. Ordinary Differential Equations (ODEs)\\n4. Basic Reproduction Number (R0)\\n5. Exponential Functions\\n6. Epidemiological Modelling Assumptions'), '$selected_topics': LocalOutput(value=['SIRD Modelling'], summary='[\"SIRD Modelling\"]'), '$notion_pages_created': LocalOutput(value=[{'topic': 'SIRD Modelling', 'page_id': '1d3573e9-d54c-8179-94ae-effe9f384fbf'}], summary='[{\"topic\": \"SIRD Modelling\", \"page_id\": \"1d3573e9-d54c-8179-94ae-effe9f384fbf\"}]')}, final_output=LocalOutput(value=[{'topic': 'SIRD Modelling', 'page_id': '1d3573e9-d54c-8179-94ae-effe9f384fbf'}], summary=\"The research assistant's tasks involved finding and downloading a paper on time series, extracting its full text, and identifying core mathematical and scientific concepts. Despite an error in downloading, the PDFReaderTool extracted text from a local file on SIRD modeling for COVID-19 in Italy. Key concepts identified included SIRD Modelling, Least Squares Regression, ODEs, Basic Reproduction Number, Exponential Functions, and Epidemiological Modelling Assumptions. The TopicSelectorTool highlighted 'SIRD Modelling,' and a Notion page was created for it.\")))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan, steps, task, portia = planner(topic=\"time series\", constraints=None, further_reading = False, youtube_videos = False)\n",
    "\n",
    "run_RAI(task, portia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
