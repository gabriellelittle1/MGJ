{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee5c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\anaconda3\\envs\\RA\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from portia import Config, Portia, PortiaToolRegistry, open_source_tool_registry, InMemoryToolRegistry\n",
    "from portia.cli import CLIExecutionHooks\n",
    "from portia.config import default_config\n",
    "from portia.open_source_tools.registry import example_tool_registry\n",
    "from portia.clarification import MultipleChoiceClarification\n",
    "from portia.plan_run import PlanRunState\n",
    "from portia import LLMModel\n",
    "from portia import Portia\n",
    "from my_custom_tools.PDFReaderTool import PDFReaderTool\n",
    "from my_custom_tools.TopicSelectorTool import TopicSelectorTool\n",
    "\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349b3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "from pydantic import BaseModel\n",
    "from portia import Tool, ToolHardError, ToolRunContext\n",
    "from typing import ClassVar\n",
    "\n",
    "\n",
    "# class PDFReaderToolSchema(BaseModel):\n",
    "#     \"\"\"No input needed. Reads all PDFs from the papers folder.\"\"\"\n",
    "#     pass\n",
    "\n",
    "\n",
    "# class PDFReaderTool(Tool[dict[str, str]]):\n",
    "#     \"\"\"Reads and returns full text from all PDFs in the ./papers/ folder.\"\"\"\n",
    "\n",
    "#     id: ClassVar[str] = \"pdf_reader_tool\"\n",
    "#     name: ClassVar[str] = \"PDF reader tool\"\n",
    "#     description: ClassVar[str] = \"Reads all PDFs from the local 'papers' folder and returns their full text\"\n",
    "#     args_schema = PDFReaderToolSchema\n",
    "#     output_schema: ClassVar[tuple[str, str]] = (\"dict\", \"Dictionary of filename -> full text\")\n",
    "\n",
    "#     def run(self, ctx: ToolRunContext) -> dict[str, str]:\n",
    "#         \"\"\"Extracts and returns full text from all PDFs in the ./papers folder.\"\"\"\n",
    "#         base_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "#         papers_dir = base_dir / \"fake_papers\"\n",
    "#         if not papers_dir.exists() or not papers_dir.is_dir():\n",
    "#             raise ToolHardError(\"The 'papers/' folder does not exist.\")\n",
    "\n",
    "#         pdf_files = list(papers_dir.glob(\"*.pdf\"))\n",
    "#         if not pdf_files:\n",
    "#             raise ToolHardError(\"No PDF files found in the 'papers/' folder.\")\n",
    "\n",
    "#         texts = {}\n",
    "#         for file_path in pdf_files:\n",
    "#             try:\n",
    "#                 full_text = self.read_pdf(file_path)\n",
    "#                 texts[file_path.name] = full_text\n",
    "#             except Exception as e:\n",
    "#                 texts[file_path.name] = f\"Error reading file: {str(e)}\"\n",
    "\n",
    "#         return texts\n",
    "\n",
    "#     def read_pdf(self, file_path: Path) -> str:\n",
    "#         \"\"\"Extracts and cleans text from a PDF file, stopping before References/Bibliography.\"\"\"\n",
    "#         text = []\n",
    "#         with fitz.open(file_path) as doc:\n",
    "#             for page_num, page in enumerate(doc):\n",
    "#                 page_text = page.get_text(\"text\")\n",
    "#                 cleaned_text = self._remove_arxiv_footer(page_text)\n",
    "\n",
    "#                 # Check for 'References' or 'Bibliography' section header\n",
    "#                 if self._is_bibliography_page(cleaned_text):\n",
    "#                     print(f\"Stopping at page {page_num + 1} (found References section).\")\n",
    "#                     break\n",
    "\n",
    "#                 text.append(f\"--- Page {page_num + 1} ---\\n{cleaned_text.strip()}\")\n",
    "#         return \"\\n\\n\".join(text)\n",
    "\n",
    "#     def _remove_arxiv_footer(self, text: str) -> str:\n",
    "#         \"\"\"Removes common arXiv-style footers.\"\"\"\n",
    "#         lines = text.splitlines()\n",
    "#         return \"\\n\".join(\n",
    "#             line for line in lines\n",
    "#             if \"arxiv\" not in line.lower() and \"preprint\" not in line.lower()\n",
    "#         )\n",
    "    \n",
    "#     def _is_bibliography_page(self, text: str) -> bool:\n",
    "#         \"\"\"Returns True if the page looks like it's starting the bibliography or references.\"\"\"\n",
    "#         lowered = text.lower()\n",
    "#         # Check if 'references' or 'bibliography' is a standalone word early in the text\n",
    "#         return (\n",
    "#             \"references\\n\" in lowered\n",
    "#             or lowered.strip().startswith(\"references\")\n",
    "#             or lowered.strip().startswith(\"bibliography\")\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import ClassVar, List, Union\n",
    "# from pydantic import BaseModel, Field\n",
    "# from portia import Tool, ToolRunContext\n",
    "# import re\n",
    "\n",
    "\n",
    "# class TopicSelectorToolSchema(BaseModel):\n",
    "#     raw_topics: Union[str, List[str]] = Field(\n",
    "#         ..., description=\"List of topics (numbered or unnumbered) to prompt the user for selection.\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# class TopicSelectorTool(Tool[List[str]]):\n",
    "#     id: ClassVar[str] = \"topic_selector_tool\"\n",
    "#     name: ClassVar[str] = \"Topic Selector Tool\"\n",
    "#     description: ClassVar[str] = \"Prompts the user to choose from a list of topics.\"\n",
    "#     args_schema = TopicSelectorToolSchema\n",
    "#     output_schema: ClassVar[tuple[str, str]] = (\"list\", \"List of user-selected topics\")\n",
    "\n",
    "#     def run(self, ctx: ToolRunContext, raw_topics: Union[str, List[str]]) -> List[str]:\n",
    "#         if isinstance(raw_topics, str):\n",
    "#             topics = self._parse_lines(raw_topics)\n",
    "#         else:\n",
    "#             topics = raw_topics\n",
    "\n",
    "#         if not topics:\n",
    "#             raise ValueError(\"No topics to choose from.\")\n",
    "\n",
    "#         clean_topics = [self._clean_topic(t) for t in topics]\n",
    "\n",
    "#         print(\"\\nüìö Please choose one or more topics to learn about:\")\n",
    "#         for i, topic in enumerate(clean_topics, 1):\n",
    "#             print(f\"{i}. {topic}\")\n",
    "\n",
    "#         choice_str = input(\"Enter topic numbers separated by commas (e.g. 1,3,4):\\n\")\n",
    "#         try:\n",
    "#             indices = [int(i.strip()) - 1 for i in choice_str.split(\",\")]\n",
    "#             selected = [clean_topics[i] for i in indices if 0 <= i < len(clean_topics)]\n",
    "#             return selected\n",
    "#         except Exception as e:\n",
    "#             raise ValueError(f\"Invalid input: {e}\")\n",
    "\n",
    "\n",
    "#     def _parse_lines(self, text: str) -> List[str]:\n",
    "#         lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
    "#         parsed = []\n",
    "#         for line in lines:\n",
    "#             if \".\" in line:\n",
    "#                 _, after = line.split(\".\", 1)\n",
    "#                 parsed.append(after.strip())\n",
    "#             else:\n",
    "#                 parsed.append(line)\n",
    "#         return parsed\n",
    "    \n",
    "#     def _clean_topic(self, topic: str) -> str:\n",
    "#         return re.sub(r\"^\\s*\\d+[\\.\\)]\\s*\", \"\", topic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from portia.open_source_tools.registry import example_tool_registry\n",
    "\n",
    "my_config = Config.from_default()\n",
    "\n",
    "\n",
    "my_config.models['planning_default_model_name'] = LLMModel.GPT_4_O\n",
    "\n",
    "example_tool_registry.register_tool(PDFReaderTool())\n",
    "example_tool_registry.register_tool(TopicSelectorTool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3dbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from portia import PlanRunState, InputClarification, MultipleChoiceClarification, ActionClarification\n",
    "\n",
    "def handle_clarifications(plan_run, portia):\n",
    "    while plan_run.state == PlanRunState.NEED_CLARIFICATION:\n",
    "        outstanding = plan_run.get_outstanding_clarifications()\n",
    "        if not outstanding:\n",
    "            print(\"‚ö†Ô∏è Plan is stuck waiting for clarification, but none are outstanding.\")\n",
    "            break\n",
    "\n",
    "        for clarification in outstanding:\n",
    "            print(f\"\\nüîπ {clarification.user_guidance}\")\n",
    "\n",
    "            if isinstance(clarification, MultipleChoiceClarification):\n",
    "                print(\"Options:\")\n",
    "                for i, option in enumerate(clarification.options, 1):\n",
    "                    print(f\"{i}. {option}\")\n",
    "                raw_input_str = input(\"Enter your choice(s), separated by commas:\\n\")\n",
    "                try:\n",
    "                    indices = [int(i.strip()) - 1 for i in raw_input_str.split(\",\")]\n",
    "                    selected = [clarification.options[i] for i in indices]\n",
    "                    plan_run = portia.resolve_clarification(clarification, selected)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Invalid input: {e}\")\n",
    "                    continue  # Retry\n",
    "\n",
    "            elif isinstance(clarification, InputClarification):\n",
    "                response = input(\"Please enter your response:\\n\")\n",
    "                plan_run = portia.resolve_clarification(clarification, response)\n",
    "\n",
    "            elif isinstance(clarification, ActionClarification):\n",
    "                print(f\"{clarification.user_guidance}\")\n",
    "                print(f\"üîó {clarification.action_url}\")\n",
    "                input(\"Press Enter after completing the action...\")\n",
    "                plan_run = portia.resolve_clarification(clarification, None)\n",
    "\n",
    "            else:\n",
    "                print(\"‚ùå Unknown clarification type.\")\n",
    "                continue\n",
    "\n",
    "        # Allow state update to propagate before checking again\n",
    "        plan_run.refresh()\n",
    "\n",
    "    return plan_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6612ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 01:03:09.089\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m197\u001b[0m - \u001b[1mRunning planning_agent for query - You are a research assistant running tasks: \n",
      "                    - Run the PDFReaderTool to extract the full text from the pdfs in the local folder\n",
      "                    - From the full text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum‚Äîavoid content specific to the study's location, data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
      "                    - From the extracted topics, allow for the user to choose which topics they want to learn about using the TopicSelectorTool. The tool should only be used to *prompt the user*, and the result of the selection should be used as-is. Do not run the tool again after selections are made..\n",
      "                    - For each chosen topic, write a clear, self-contained lesson on the topic. The lesson should be structured like a Notion page intended for independent learning. It must include an introduction to the concept, key definitions, relevant formulas or equations (if any), and intuitive explanations using examples or analogies where appropriate. Briefly mention common applications in scientific or mathematical contexts. Conclude with 1‚Äì3 reflective questions or practice prompts to reinforce understanding. Do not reference any specific research paper or generate visual content. The tone should be educational, beginner-friendly, and logically structured with clear headings.\n",
      "                    \u001b[0m\n",
      "\u001b[32m2025-04-12 01:03:17.002\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;39mportia.portia\u001b[0m:\u001b[38;5;39mplan\u001b[0m:\u001b[38;5;39m222\u001b[0m - \u001b[1mPlan created with 4 steps\u001b[0m | {'plan': 'plan-ac4c3180-de45-4aac-a0cb-12cc187c10fd'}\n",
      "\u001b[32m2025-04-12 01:03:21.283\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m528\u001b[0m - \u001b[1mPlan Run State is updated to PlanRunState.IN_PROGRESS. View in your Portia AI dashboard: https://app.portialabs.ai/dashboard/plan-runs?plan_run_id=prun-dff40cf1-7828-40bc-b2e8-5e20f0f409ba\u001b[0m\n",
      "\u001b[32m2025-04-12 01:03:21.284\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 0: Extract the full text from the PDFs in the local 'papers' folder.\u001b[0m | {'plan': 'plan-ac4c3180-de45-4aac-a0cb-12cc187c10fd', 'plan_run': 'prun-dff40cf1-7828-40bc-b2e8-5e20f0f409ba'}\n",
      "\u001b[32m2025-04-12 01:03:24.593\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking PDF reader tool with args: {}\u001b[0m\n",
      "\u001b[32m2025-04-12 01:03:27.401\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - {\"Poster.pdf\": \"--- Page 1 ---\\nForecasting coronavirus in Italy with SIRD modelling\\nGabrielle Littlefair\\nOral: https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d1f1304-438b-40e3-b586-abd7011a8903\\nObjectives\\n‚Ä¢ Find estimates for the contact, death and recovery rates\\nof coronavirus in Italy using least squares regression.\\n‚Ä¢ Identify any issues with the model and data.\\n‚Ä¢ Extrapolate the model to see how coronavirus may\\nprogress in the upcoming months.\\nIntroduction\\nThe Ô¨Årst case of coronavirus in Italy was reported on the 31st\\nJanuary 2020. Between then and the 6th June 2020, 33,846\\npeople died and the total number of cases rose to 234,801 [8].\\n23.3% of Italy‚Äôs population is over the age of 65 [5], making it\\nthe second oldest population in the world. This may explain\\nwhy Italy seems especially vulnerable. I have modelled Italy‚Äôs\\noutbreak using SIRD modelling. Modelling accurate rates of\\ninfection, recovery and death, along with the basic reproduc-\\ntion number, R0, can be quite challenging due to the high\\nproportion of infections that are undetected. The number of\\ninfections has been estimated to be as high as 63 times as large\\nas the number recorded [3].\\nSIRD Modelling\\nSIRD modelling is based on four diÔ¨Äerent groups within the\\npopulation: those who are susceptible (S); those who are in-\\nfected (I); those who have recovered (R); and those who have\\ndied (D).\\nThe governing equations of my model are as follows:\\nS + I\\nŒ≤\\n‚àí‚Üí2I\\nI\\nŒ≥\\n‚àí‚ÜíR\\nI\\nŒ¥\\n‚àí‚ÜíD\\nWhere Œ≤ is the contact rate, Œ≥ is the rate of recovery, and Œ¥ is\\nthe rate of death. From these equations, the following system\\nof ODEs can be found and solved [6]:\\ndS\\ndt = ‚àíŒ≤\\nNSI\\ndI\\ndt = Œ≤\\nNSI ‚àí(Œ≥ + Œ¥)I\\ndR\\ndt = Œ≥I\\ndD\\ndt = Œ¥I\\nFitting the Model to the Data\\nI used least squares regression from python‚Äôs lmÔ¨Åt module to\\nÔ¨Åt my SIRD model to my data [7]. I began by assuming that\\nmy rates Œ≤, Œ≥ and Œ¥ were all constant. However, after plotting\\nthe results of this model, I quickly realised that my value of Œ≤\\nneeded to decrease with time. Therefore, I decided to deÔ¨Åne\\nŒ≤(t) as a function instead. I found this function intuitively\\nusing a negative exponential model multiplied by the Œ≤ value\\nfound. I also assumed that the initial number of susceptible in\\nItaly was equal to the population: 60,461,828 [1]. The results\\nfor recovery and death rates were as follows:\\nŒ≥ = 0.0234\\nŒ¥ = 0.0064\\nThe following values of Œ≤ correspond to the start of the data\\nand the end of lockdown:\\n18/02/2020\\nŒ≤ = 0.1473\\n14/05/2020\\nŒ≤ = 0.0080\\nFrom these values of Œ≤ we can see that at the end of lockdown,\\nthe infection rate was much lower, as expected, due to much\\nfewer contacts between those in the susceptible group and those\\nin the infected group.\\nR0\\nAn important feature of modelling epidemics is the basic repro-\\nduction number R0. This number is the number of secondary\\ninfections resulting from a single primary infection. The reason\\nthis value is so important is that it is an indication of whether\\nthe disease will die out (R0 \\< 1), or if it will become an en-\\ndemic (R0 \\> 1) [4]. This value changes when measures are\\nimplemented that reduce the rate of infection, like lockdown.\\nR0 can be found using the following equation [7]:\\nR0 = Œ≤(t)\\nŒ≥\\nUsing my model, I have found values of R0 at diÔ¨Äerent times:\\n18/02/2020\\nR0 = 6.2929\\n22/04/2020\\nR0 = 1.0052\\n23/04/2020\\nR0 = 0.9542\\n14/05/2020\\nR0 = 0.3405\\nR0 is Ô¨Årst below 1, meaning that the disease has begun dying\\nout, on the 23rd April 2020, in the middle of the lockdown pe-\\nriod. This suggests that lockdown was eÔ¨Äective. When Italy\\nbegan relaxing its lockdown measures, R0 was very small, how-\\never as the lockdown eases and contact rates increase that value\\ncould easily rise once again.\\nAssumptions\\nSIRD modelling has many drawbacks. First of all, the assumes that once you have been infected you are then immune to the virus,\\nwhich has not been proved or disproved for coronavirus yet. If this assumption is proved wrong, the model would be unreliable\\nuntil another category is added in. My model assumes that you become infectious when you become infected (i.e. when you test\\npositive), however, according to Harvard Medical School [2], you actually become infectious up to 72 hours before you show any\\nsymptoms. Another assumption is that there are no births in the population. There are also problems with the accuracy and\\nreliability of the data [8] being used. Many cases of coronavirus go unreported and untested. There could also be a high proportion\\nof asymptomatic cases [3], which will also remain unrecorded.\\nThe Model\\nFigure 1:Data vs Model plotted between 18/02/2020 and 07/06/2020\\nForecast\\nFigure 2:Model plotted between 18/02/2020 and 06/08/2020\\nConclusion\\nAlthough I do not believe that the model I have gener-\\nated is very accurate, it seems that Italy is very much on\\nthe way towards eradicating coronavirus. However, the un-\\nknown proportion of the population that has coronavirus\\nand is asymptomatic, along with the unrecorded cases,\\ncould mean that we may begin to see an upward trend\\nin the number of cases. Potentially even a second peak.\\nGoing forward, I would like to add in more compartments\\ninto my model (such as the exposed compartment), in order\\nto increase the accuracy of the model. This exposed cate-\\ngory would remove the need for a dampener on the rate of\\ninfection, as a contact rate would then also be estimated,\\nmaking a much more reliable model. I would also like to\\ncompare various countries which have now left lockdown\\nin order to see how exiting the lockdown has aÔ¨Äected their\\ninfection rates and whether a second spike seems likely.\\nReferences\\n[1] ‚ÄúOur world in data coronavirus.‚Äù [Online]. Available:\\nhttps://ourworldindata.org/coronavirus\\n[2] ‚ÄúHarvard health coronavirus.‚Äù [Online]. Available:\\nhttps://www.health.harvard.edu/diseases-and-conditions/\\nif-youve-been-exposed-to-the-coronavirus\\n[3] G. C. CalaÔ¨Åore, C. Novara, and C. Possieri, ‚ÄúA modiÔ¨Åed sir model for\\nthe covid-19 contagion in italy,‚Äù Mar 31, 2020. [Online]. Available:\\n[4] K. Nixon and L. Servitje, Endemic.\\nLondon: Palgrave Macmillan\\nLimited, 2016. [Online]. Available: https://ebookcentral.proquest.\\ncom/lib/[SITE_ID]/detail.action?docID=4720003\\n[5] J. B. Dowd, L. Andriano, D. M. Brazel, V. Rotondi, P. Block,\\nX. Ding, Y. Liu, and M. C. Mills, ‚ÄúDemographic science aids in\\nunderstanding the spread and fatality rates of covid-19,‚Äù Proceedings\\nof the National Academy of Sciences of the United States of\\nAmerica, vol. 117, no. 18, pp. 9696‚Äì9698, May 5, 2020. [Online].\\nAvailable: https://www.ncbi.nlm.nih.gov/pubmed/32300018\\n[6] . K. S. E. Model, ‚ÄúIntroduction to epidemic modeling.‚Äù\\n[7] J. Fern√°ndez-Villaverde, ‚ÄúEstimating and simulating a sird model of\\ncovid-19 for many countries, states, and cities,‚Äù 2020. [Online].\\nAvailable: http://www.econis.eu/PPNSET?PPN=1698547927\\n[8] ‚ÄúJohn hopkins university coronavirus data.‚Äù [Online]. Available:\\nhttps://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\"}\u001b[0m\n",
      "\u001b[32m2025-04-12 01:03:28.894\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 1: From the full text in $pdf_text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum‚Äîavoid content specific to the study's location, data, or outcomes. List only the overarching topics, with no explanations or extra text.\u001b[0m | {'plan': 'plan-ac4c3180-de45-4aac-a0cb-12cc187c10fd', 'plan_run': 'prun-dff40cf1-7828-40bc-b2e8-5e20f0f409ba'}\n",
      "\u001b[32m2025-04-12 01:03:34.050\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking LLM Tool with args: {'task': \"From the full text in $pdf_text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum‚Äîavoid content specific to the study's location, data, or outcomes. List only the overarching topics, with no explanations or extra text.\"}\u001b[0m\n",
      "\u001b[32m2025-04-12 01:03:38.186\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - 1. SIRD Modelling\n",
      "2. Ordinary Differential Equations (ODEs)\n",
      "3. Least Squares Regression\n",
      "4. Contact Rate, Recovery Rate, and Death Rate\n",
      "5. Basic Reproduction Number (R0)\n",
      "6. Exponential Functions in Modelling\n",
      "7. Assumptions in Epidemiological Modelling\u001b[0m\n",
      "\u001b[32m2025-04-12 01:03:39.644\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 2: Allow the user to choose which topics they want to learn about from the list of extracted topics in $extracted_topics using the TopicSelectorTool.\u001b[0m | {'plan': 'plan-ac4c3180-de45-4aac-a0cb-12cc187c10fd', 'plan_run': 'prun-dff40cf1-7828-40bc-b2e8-5e20f0f409ba'}\n",
      "\u001b[32m2025-04-12 01:03:43.946\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking Topic Selector Tool with args: {'raw_topics': ['1. SIRD Modelling', '2. Ordinary Differential Equations (ODEs)', '3. Least Squares Regression', '4. Contact Rate, Recovery Rate, and Death Rate', '5. Basic Reproduction Number (R0)', '6. Exponential Functions in Modelling', '7. Assumptions in Epidemiological Modelling']}\u001b[0m\n",
      "\n",
      "üìö Please choose one or more topics to learn about:\n",
      "1. SIRD Modelling\n",
      "2. Ordinary Differential Equations (ODEs)\n",
      "3. Least Squares Regression\n",
      "4. Contact Rate, Recovery Rate, and Death Rate\n",
      "5. Basic Reproduction Number (R0)\n",
      "6. Exponential Functions in Modelling\n",
      "7. Assumptions in Epidemiological Modelling\n",
      "\u001b[32m2025-04-12 01:04:03.094\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m588\u001b[0m - \u001b[1mStep output - [\"Ordinary Differential Equations (ODEs)\", \"Least Squares Regression\"]\u001b[0m\n",
      "\u001b[32m2025-04-12 01:04:04.531\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;129mportia.portia\u001b[0m:\u001b[38;5;129m_execute_plan_run\u001b[0m:\u001b[38;5;129m551\u001b[0m - \u001b[1mExecuting step 3: For each chosen topic in $selected_topics, write a clear, self-contained lesson. The lesson should be structured like a Notion page intended for independent learning, including an introduction to the concept, key definitions, relevant formulas or equations if any, intuitive explanations using examples or analogies where appropriate, common applications in scientific or mathematical contexts, and concluding with 1‚Äì3 reflective questions or practice prompts.\u001b[0m | {'plan': 'plan-ac4c3180-de45-4aac-a0cb-12cc187c10fd', 'plan_run': 'prun-dff40cf1-7828-40bc-b2e8-5e20f0f409ba'}\n",
      "\u001b[32m2025-04-12 01:04:10.582\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[38;5;87mportia.tool_wrapper\u001b[0m:\u001b[38;5;87mrun\u001b[0m:\u001b[38;5;87m115\u001b[0m - \u001b[1mInvoking LLM Tool with args: {'task': 'For each chosen topic in $selected_topics, write a clear, self-contained lesson. The lesson should be structured like a Notion page intended for independent learning, including an introduction to the concept, key definitions, relevant formulas or equations if any, intuitive explanations using examples or analogies where appropriate, common applications in scientific or mathematical contexts, and concluding with 1‚Äì3 reflective questions or practice prompts.'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load example and custom tool registries into a single one\n",
    "# Instantiate a Portia instance. Load it with the default config and with the tools above\n",
    "\n",
    "portia = Portia(config=my_config,\n",
    "                tools=PortiaToolRegistry(my_config)+example_tool_registry)\n",
    "\n",
    "# Execute the plan from the user query\n",
    "plan_run = portia.run(\"\"\"You are a research assistant running tasks: \n",
    "                    - Run the PDFReaderTool to extract the full text from the pdfs in the local folder\n",
    "                    - From the full text, extract the core mathematical and scientific concepts required to understand the paper. Focus only on generalizable topics that could be included in a learning pathway or curriculum‚Äîavoid content specific to the study's location, data, or outcomes. List only the overarching topics, with no explanations or extra text.\n",
    "                    - From the extracted topics, allow for the user to choose which topics they want to learn about using the TopicSelectorTool. The tool should only be used to *prompt the user*, and the result of the selection should be used as-is. Do not run the tool again after selections are made..\n",
    "                    - For each chosen topic, write a clear, self-contained lesson on the topic. The lesson should be structured like a Notion page intended for independent learning. It must include an introduction to the concept, key definitions, relevant formulas or equations (if any), and intuitive explanations using examples or analogies where appropriate. Briefly mention common applications in scientific or mathematical contexts. Conclude with 1‚Äì3 reflective questions or practice prompts to reinforce understanding. Do not reference any specific research paper or generate visual content. The tone should be educational, beginner-friendly, and logically structured with clear headings.\n",
    "                    \"\"\",)\n",
    "\n",
    "plan_run = handle_clarifications(plan_run, portia)\n",
    "\n",
    "# After resolving all clarifications:\n",
    "print(\"\\n‚úÖ Final Output:\")\n",
    "print(plan_run.model_dump_json(indent=2))\n",
    "\n",
    "\n",
    "# [print(step.model_dump_json(indent=2)) for step in plan_run.steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ebdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path: Path) -> str:\n",
    "    \"\"\"Extracts and cleans text from a PDF file, stopping before References/Bibliography.\"\"\"\n",
    "    text = []\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page_num, page in enumerate(doc):\n",
    "            page_text = page.get_text(\"text\")\n",
    "            cleaned_text = _remove_arxiv_footer(page_text)\n",
    "\n",
    "            # Check for 'References' or 'Bibliography' section header\n",
    "            # if _is_bibliography_page(cleaned_text):\n",
    "            #     print(f\"Stopping at page {page_num + 1} (found References section).\")\n",
    "            #     break\n",
    "\n",
    "            text.append(f\"--- Page {page_num + 1} ---\\n{cleaned_text.strip()}\")\n",
    "    return \"\\n\\n\".join(text)\n",
    "\n",
    "def _remove_arxiv_footer(text: str) -> str:\n",
    "    \"\"\"Removes common arXiv-style footers.\"\"\"\n",
    "    lines = text.splitlines()\n",
    "    return \"\\n\".join(\n",
    "        line for line in lines\n",
    "        if \"arxiv\" not in line.lower() and \"preprint\" not in line.lower()\n",
    "     )\n",
    "\n",
    "def _is_bibliography_page(text: str) -> bool:\n",
    "    \"\"\"Returns True if the page looks like it's starting the bibliography or references.\"\"\"\n",
    "    lowered = text.lower()\n",
    "    # Check if 'references' or 'bibliography' is a standalone word early in the text\n",
    "    return (\n",
    "        \"references\\n\" in lowered\n",
    "        or lowered.strip().startswith(\"references\")\n",
    "        or lowered.strip().startswith(\"bibliography\")\n",
    "    )\n",
    "\n",
    "\n",
    "base_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "papers_dir = base_dir / \"fake_papers\"\n",
    "if not papers_dir.exists() or not papers_dir.is_dir():\n",
    "    raise ToolHardError(\"The 'papers/' folder does not exist.\")\n",
    "\n",
    "pdf_files = list(papers_dir.glob(\"*.pdf\"))\n",
    "if not pdf_files:\n",
    "    raise ToolHardError(\"No PDF files found in the 'papers/' folder.\")\n",
    "\n",
    "texts = {}\n",
    "for file_path in pdf_files:\n",
    "    try:\n",
    "        full_text = read_pdf(file_path)\n",
    "        texts[file_path.name] = full_text\n",
    "    except Exception as e:\n",
    "        texts[file_path.name] = f\"Error reading file: {str(e)}\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
